<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Life Designer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Life Designer, design by oneself!">
<meta property="og:type" content="website">
<meta property="og:title" content="Life Designer">
<meta property="og:url" content="http://yespon.github.io/index.html">
<meta property="og:site_name" content="Life Designer">
<meta property="og:description" content="Life Designer, design by oneself!">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Designer">
<meta name="twitter:description" content="Life Designer, design by oneself!">
  
    <link rel="alternate" href="/atom.xml" title="Life Designer" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yespon.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/categories">Category</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Designer</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Life Designer, design by oneself!</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-TensorFlow基本概念" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/05/TensorFlow基本概念/" class="article-date">
  <time datetime="2018-03-05T07:07:26.000Z" itemprop="datePublished">2018-03-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/05/TensorFlow基本概念/">TensorFlow基本概念</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="TensorFlow基本概念"><a href="#TensorFlow基本概念" class="headerlink" title="TensorFlow基本概念"></a>TensorFlow基本概念</h1><p>开始使用 TensorFlow 时，我们需要了解下其基本组成元素：</p>
<!--nore-->
<ul>
<li><p>使用<strong>计算图（graph )</strong> 定义计算任务</p>
</li>
<li><p>在被称之为<strong>会话 (Session)</strong> 的<strong>上下文 (context)</strong> 中，运行<strong>计算图（graph）</strong></p>
</li>
<li><p>使用<strong>张量（tensor）</strong>表示数据</p>
</li>
<li><p>通过<strong>变量（Variable）</strong>维护状态，对应的还有<strong>常量（constant）</strong></p>
</li>
<li><p>使用<strong>注入（feed）</strong>（喂数据）为任意<strong>操作</strong>(arbitrary <strong>operation</strong>) 赋值，使用<strong>取回（fetch）</strong>从任意操作中获取数据</p>
</li>
</ul>
<p>TensorFlow是一个编程系统，结合下图，我们从基本元素开始说起。</p>
<p><img src="/2018/03/05/TensorFlow基本概念/1.gif" alt=""></p>
<h2 id="1-张量-Tensor"><a href="#1-张量-Tensor" class="headerlink" title="1. 张量(Tensor)"></a>1. 张量(Tensor)</h2><p>名字就是TensorFlow，直观来看，就是张量的流动。张量(tensor)，即任意维度的数据，一维、二维、三维、四维等数据统称为张量。而张量的流动则是指保持计算节点不变，让数据进行流动。这样的设计是针对连接式的机器学习算法，比如逻辑斯底回归，神经网络等。连接式的机器学习算法可以把算法表达成一张图，张量从图中从前到后走一遍就完成了前向运算；而残差从后往前走一遍，就完成了后向传播。</p>
<h3 id="1-1-维度-Shape"><a href="#1-1-维度-Shape" class="headerlink" title="1.1 维度 (Shape)"></a>1.1 维度 (Shape)</h3><p>TensorFlow中使用了三种记号描述张量的维度：阶，形状以及维数。下表展示了他们之间的关系：</p>
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[ ]</td>
<td>0-D</td>
<td>一个0维张量是一个常量，如5</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>一个1维张量是一个矢量，如[5, 4]</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>一个2维张量是一个矩阵，如[[5, 4], [2, 3]]</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>一个3维张量是一个立方矩阵，如[[[5, 4], [2, 3]], [[5, 4], [2, 3]]</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, D2,….Dn]</td>
<td>n-D</td>
<td>一个n维张量是一个多维数组</td>
</tr>
</tbody>
</table>
<h3 id="1-2-阶（Rank）"><a href="#1-2-阶（Rank）" class="headerlink" title="1.2 阶（Rank）"></a>1.2 阶（Rank）</h3><p>在TensorFlow系统中，张量的维数来被描述为阶。但是张量的阶和矩阵的阶并不是同一个概念：张量的阶（关于如顺序、度数或者是n维）是张量维数的一个数量描述。比如，Python中的list列表就是2阶。</p>
<p>你可以认为零阶张量是一个常量；一阶张量是一个向量；二阶张量就是我们平常所说的矩阵，你可以用语句t[i, j]来访问其中的任何元素；对于三阶张量，你可以用t[i, j, k]来访问其中的任何元素。</p>
<h3 id="1-3-数据类型-Type"><a href="#1-3-数据类型-Type" class="headerlink" title="1.3 数据类型 (Type)"></a>1.3 数据类型 (Type)</h3><p>除了维度，tensor还有一个数据类型属性。你可以为一个张量指定下列数据类型中的任意一个类型：</p>
<p><img src="/2018/03/05/TensorFlow基本概念/2.png" alt=""></p>
<h2 id="2-算子-operation"><a href="#2-算子-operation" class="headerlink" title="2. 算子(operation)"></a>2. 算子(operation)</h2><p>节点被称之为op（节点也叫操作、算子，是operation的缩写）。一个op获得0个或多个tensor，执行计算产生0个或多个tensor。</p>
<h2 id="3-边（edge）"><a href="#3-边（edge）" class="headerlink" title="3. 边（edge）"></a>3. 边（edge）</h2><p>TensorFlow，字面意思就是张量的流动（flow）。<br>TF的图中的边分为两种：</p>
<ul>
<li><p>正常边，正常边上可以流动数据，即正常边就是tensor。计算图的一条边，就是一个tensor。而张量的流动则是指保持计算节点不变，让数据进行流动。tensor是一个数据类型的一维、二维、三维、四维等多维数组。例如，你可以把一组图像集表示为一个四维浮点数的数组，这四个维度分别是 [batch, height, width, channels]。</p>
</li>
<li><p>特殊边，又称作控制依赖，(control dependencies)</p>
<ul>
<li>没有数据从特殊边上流动，但是特殊边却可以控制节点之间的依赖关系，在特殊边的起始节点完成运算之前，特殊边的结束节点不会被执行。</li>
<li>也不仅仅非得有依赖关系才可以用特殊边，还可以有其他用法，比如为了控制内存的时候，可以让两个实际上并没有前后依赖关系的运算分开执行。</li>
<li>特殊边可以在client端被直接使用。</li>
</ul>
</li>
</ul>
<h2 id="4-核-kernel"><a href="#4-核-kernel" class="headerlink" title="4. 核(kernel)"></a>4. 核(kernel)</h2><p>TF中还有一个概念是kernel，kernel是operation在某种设备上的具体实现。TF的库通过注册机制来定义op和kernel，所以可以通过链接一个其他的库来进行kernel和op的扩展。</p>
<h2 id="5-计算图（graph）"><a href="#5-计算图（graph）" class="headerlink" title="5. 计算图（graph）"></a>5. 计算图（graph）</h2><p>节点和边相互连接成计算图，一个计算图描述了一次计算过程。</p>
<p>这是一个声明式的编程方式，如同做菜，我们需要先把主材和佐料都准备好，才能添油烹制。TensorFlow的计算方式也是如此。在构建阶段，我们需要把网络（如神经网络）以计算图的形式构建出来，接着启动会话（session），运行先前构建的图，得到目标结果。</p>
<h2 id="6-会话（session）"><a href="#6-会话（session）" class="headerlink" title="6. 会话（session）"></a>6. 会话（session）</h2><p>使用TensorFlow编写的程序，通常被组织成一个构建阶段和一个运行阶段：在构建阶段，操作的执行步骤被描述成一个计算图；在运行阶段，使用会话执行计算图中的操作。</p>
<p>为了得到结果，计算图必须在会话里被启动。会话将计算图的op分发到诸如CPU或GPU之类的设备上，同时提供执行op的方法。这些方法执行后，将产生的tensor返回。在Python语言中, 返回的tensor是numpy ndarray对象；在C和C++语言中，返回的tensor是tensorflow Tensor实例。</p>
<h2 id="7-变量（variable）"><a href="#7-变量（variable）" class="headerlink" title="7. 变量（variable）"></a>7. 变量（variable）</h2><p>在运行计算图过程中，变量用于维护某个参数的状态。TensorFlow通常会将一个统计模型中的参数表示为一组变量，例如你可以将一个神经网络的权重作为某个变量存储在一个tensor中。在训练过程中, 通过重复运行计算图，更新这个tensor。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="http://blog.csdn.net/weixin_30014549/article/details/52529036" target="_blank" rel="external">tensorflow原理</a></p>
<p>[2] <a href="http://blog.csdn.net/stdcoutzyx/article/details/51645396" target="_blank" rel="external">tensorflow架构</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/05/TensorFlow基本概念/" data-id="cjeebbnyg000r48wgjjhdwnlw" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-卷积神经网络——卷积神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/04/卷积神经网络——卷积神经网络/" class="article-date">
  <time datetime="2018-03-04T04:40:35.000Z" itemprop="datePublished">2018-03-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/04/卷积神经网络——卷积神经网络/">卷积神经网络——卷积神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>以下为在吴恩达老师的 deeplearning.ai 课程项目中，第四部分《卷积神经网络》第一周课程 “卷积神经网络基础” 关键点的笔记。本次笔记几乎涵盖了所有视频课程的内容。通过该笔记，一方面为自己学习进行记录，以便以后进行快速review，另一方面，也便于与大家进行探讨学习，错误及不足之处，还望指教。<br><!--nore--></p>
<h2 id="1-计算机视觉"><a href="#1-计算机视觉" class="headerlink" title="1. 计算机视觉"></a>1. 计算机视觉</h2><p>计算机视觉（Computer Vision）包含很多不同类别的问题，如图片分类、目标检测、图片风格迁移等等。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/1.jpg" alt=""></p>
<p>对于小尺寸的图片问题，也许我们用深度神经网络的结构可以较为简单的解决一定的问题。但是当应用在大尺寸的图片上，输入规模将变得十分庞大，使用神经网络将会有非常多的参数需要去学习，这个时候神经网络就不再适用。</p>
<p>卷积神经网络在计算机视觉问题上是一个非常好的网络结构。</p>
<h2 id="2-边缘检测示例"><a href="#2-边缘检测示例" class="headerlink" title="2. 边缘检测示例"></a>2. 边缘检测示例</h2><p>卷积运算是卷积神经网络的基本组成部分。下面以边缘检测的例子来介绍卷积运算。</p>
<p>所谓边缘检测，在下面的图中，分别通过垂直边缘检测和水平边缘检测得到不同的结果：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/2.jpg" alt=""></p>
<h3 id="垂直边缘检测："><a href="#垂直边缘检测：" class="headerlink" title="垂直边缘检测："></a>垂直边缘检测：</h3><p>假设对于一个 $6\times6$ 大小的图片（以数字表示），以及一个 $3\times3$ 大小的 filter（卷积核） 进行卷积运算，以“ * ” 符号表示。图片和垂直边缘检测器分别如左和中矩阵所示：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/3.jpg" alt=""></p>
<p>filter 不断地和其大小相同的部分做对应元素的乘法运算并求和，最终得到的数字相当于新图片的一个像素值，如右矩阵所示，最终得到一个 $4\times4$ 大小的图片。</p>
<h3 id="边缘检测的原理："><a href="#边缘检测的原理：" class="headerlink" title="边缘检测的原理："></a>边缘检测的原理：</h3><p>以一个有一条垂直边缘线的简单图片来说明。通过垂直边缘 <strong>filter</strong> 我们得到的最终结果图片可以明显地将边缘和非边缘区分出来：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/4.jpg" alt=""></p>
<p>卷积运算提供了一个方便的方法来检测图像中的边缘，成为卷积神经网络中重要的一部分。</p>
<h3 id="多种边缘检测："><a href="#多种边缘检测：" class="headerlink" title="多种边缘检测："></a>多种边缘检测：</h3><ul>
<li>垂直和水平边缘检测</li>
</ul>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/5.jpg" alt=""></p>
<ul>
<li>更复杂的 <strong>filter</strong></li>
</ul>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/6.jpg" alt=""></p>
<p>对于复杂的图片，我们可以直接将 <strong>filter</strong> 中的数字直接看作是需要学习的参数，其可以学习到对于图片检测相比上面<strong>filter</strong>更好的更复杂的 <strong>filter</strong> ，如相对于水平和垂直检测器，我们训练的 filter 参数也许可以知道不同角度的边缘。</p>
<p>通过卷积运算，在卷积神经网络中通过反向传播算法，可以学习到相应于目标结果的 <strong>filter</strong>，将其应用于整个图片，输出其提取到的所有有用的特征。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/7.jpg" alt=""></p>
<h3 id="卷积和互相关："><a href="#卷积和互相关：" class="headerlink" title="卷积和互相关："></a>卷积和互相关：</h3><p>在数学定义上，矩阵的卷积（convolution）操作为首先将卷积核同时在水平和垂直方向上进行翻转，构成一个卷积核的镜像，然后使用该镜像再和前面的矩阵进行移动相乘求和操作。如下面例子所示：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/8.jpg" alt=""></p>
<p>在深度学习中，我们称为的卷积运算实则没有卷积核变换为镜像的这一步操作，因为在权重学习的角度，变换是没有必要的。深度学习的卷积操作在数学上准确度来说称为<strong>互相关</strong>（cross-correlation）。</p>
<h2 id="3-Padding"><a href="#3-Padding" class="headerlink" title="3. Padding"></a>3. Padding</h2><h3 id="没有Padding的缺点："><a href="#没有Padding的缺点：" class="headerlink" title="没有Padding的缺点："></a>没有Padding的缺点：</h3><ul>
<li>每次卷积操作，图片会缩小；</li>
</ul>
<p>就前面的例子来说， $6\times6$ 大小的图片，经过 $3\times3$ 大小的 filter，缩小成了 $4\times4$ 大小</p>
<p>图片： $n\times n–&gt; (n-f+1)\times (n-f+1)$</p>
<ul>
<li>角落和边缘位置的像素进行卷积运算的次数少，可能会丢失有用信息。</li>
</ul>
<p>其中，$\bold n$ 表示图片的长或宽的大小，$\bold{f}$ 表示filter的长或宽的大小。</p>
<h3 id="加Padding："><a href="#加Padding：" class="headerlink" title="加Padding："></a>加Padding：</h3><p>为了解决上面的两个缺点，我们在进行卷积运算前为图片加padding，包围角落和边缘的像素，使得通过filter的卷积运算后，图片大小不变，也不会丢失角落和边沿的信息。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/9.jpg" alt=""></p>
<p>以 p 表示 Padding 的值，则输入 $n\times n$ 大小的图片，最终得到的图片大小为  $(n+2p-f+1)\times (n+2p-f+1)$ ，为使图片大小保持不变，需根据filter的大小调整p的值。</p>
<h3 id="Valid-Same-卷积："><a href="#Valid-Same-卷积：" class="headerlink" title="Valid / Same 卷积："></a>Valid / Same 卷积：</h3><ul>
<li>Valid：no padding；（ $n\times n –&gt; (n-f+1)\times (n-f+1)$ ）</li>
<li>Same：padding，<strong>输出</strong>与<strong>输入</strong>图片大小<strong>相同</strong>，（ $p=(f-1)/2$ ）。在计算机视觉中，一般来说padding的值为奇数（因为filter一般为奇数）</li>
</ul>
<h2 id="4-卷积步长（stride）"><a href="#4-卷积步长（stride）" class="headerlink" title="4. 卷积步长（stride）"></a>4. 卷积步长（stride）</h2><p>卷积的步长是构建卷积神经网络的一个基本的操作。</p>
<p>如前面的例子中，我们使用的 stride=1，每次的卷积运算以1个步长进行移动。下面是 stride=2 时对图片进行卷积的结果：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/10.jpg" alt=""></p>
<p>以 s 表示 stride 的大小，那么在进行卷积运算后，图片的变化为：</p>
<p>$n\times n –&gt; \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor\times \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor$</p>
<p>注意，在当 $padding\ne 1$ 时，若移动的窗口落在图片外面，则不要再进行相乘的操作，丢弃边缘的数值信息，所以输出图片的最终维度为<strong>向下取整</strong>。</p>
<h2 id="5-立体卷积"><a href="#5-立体卷积" class="headerlink" title="5. 立体卷积"></a>5. 立体卷积</h2><h3 id="卷积核的通道数："><a href="#卷积核的通道数：" class="headerlink" title="卷积核的通道数："></a>卷积核的通道数：</h3><p>对于灰色图像中，卷积核和图像均是二维的。而应用于彩色图像中，因为图片有R、G、B三个颜色通道，所以此时的卷积核应为三维卷积核。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/11.jpg" alt=""></p>
<p>卷积核的第三个维度需要与进行卷积运算的图片的通道数相同。</p>
<h3 id="多卷积核："><a href="#多卷积核：" class="headerlink" title="多卷积核："></a>多卷积核：</h3><p>单个卷积核应用于图片时，提取图片特定的特征，不同的卷积核提取不同的特征。如两个大小均为  $3\times3\times3$ 的卷积核分别提取图片的垂直边缘和水平边缘。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/12.jpg" alt=""></p>
<p>由图可知，最终提取到彩色图片的垂直特征图和水平特征图，得到有2个通道的 4\times4 大小的特征图片。</p>
<h3 id="Summary："><a href="#Summary：" class="headerlink" title="Summary："></a>Summary：</h3><p>图片： $(n\times n\times n<em>{c} )* (f\times f\times n</em>{c})$ ——&gt;$(n-f+1)\times (n-f+1)\times n’_{c}$</p>
<p>其中， $n<em>{c}$ 表示通道的数量， $n’</em>{c}$ 表示下一层的通道数，同时也等于本层卷积核的个数。</p>
<h2 id="6-简单卷积网络"><a href="#6-简单卷积网络" class="headerlink" title="6. 简单卷积网络"></a>6. 简单卷积网络</h2><h3 id="单层卷积网络的例子："><a href="#单层卷积网络的例子：" class="headerlink" title="单层卷积网络的例子："></a>单层卷积网络的例子：</h3><p>和普通的神经网络单层前向传播的过程类似，卷积神经网络也是一个先由输入和权重及偏置做线性运算，然后得到的结果输入一个激活函数中，得到最终的输出：</p>
<p>$$z^{[1]}=w^{[1]}a^{[0]}+b^{[1]}$$</p>
<p>$$a^{[1]}=g(z^{[1]})$$</p>
<p>不同点是：在卷积神经网络中，权重和输入进行的是卷积运算。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/13.jpg" alt=""></p>
<h3 id="单层卷积的参数个数："><a href="#单层卷积的参数个数：" class="headerlink" title="单层卷积的参数个数："></a>单层卷积的参数个数：</h3><p>在一个卷积层中，如果我们有10个 $3\times3\times3$ 大小的卷积核，那么加上每个卷积核对应的偏置，则对于一个卷积层，我们共有的参数个数为：</p>
<p>$$(3\times3\times3+1)\times10 = 280$$</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/14.jpg" alt=""></p>
<p>无论图片大小是多少，该例子中的卷积层参数个数一直都是280个，相对于普通的神经网络，卷积神经网络的参数个数要少很多。</p>
<h3 id="标记的总结："><a href="#标记的总结：" class="headerlink" title="标记的总结："></a>标记的总结：</h3><p>如果 $l$ 表示一个卷积层：</p>
<ol>
<li>$f^{[l]}$ ：filter 的大小；</li>
<li>$p^{[l]}$ ：padding；</li>
<li>$s^{[l]}$ ：步长（stride）；</li>
<li>卷积核的个数： $n^{[l]}_{C}$ ；</li>
<li>filter大小： $f^{[l]}\times f^{[l]}\times n^{[l-1]}_{C}$ ;</li>
<li>激活值（Activations）： $a^{[l]}$—&gt;$n^{[l]}<em>{H}\times n^{[l]}</em>{W}\times n^{[l]}_{C}$；</li>
<li>权重（Weights）： $f^{[l]}\times f^{[l]}\times n^{[l-1]}<em>{C}\times n^{[l]}</em>{C}$ ；</li>
<li>偏置（bias）： $n^{[l]}<em>{C}$ — — $(1,1,1,n^{[l]}</em>{C})$</li>
</ol>
<ul>
<li>Input： $n^{[l-1]}<em>{H}\times n^{[l-1]}</em>{W}\times n^{[l-1]}_{C}$ ；</li>
<li>Output： $n^{[l]}<em>{H}\times n^{[l]}</em>{W}\times n^{[l]}_{C}$ ；</li>
</ul>
<p>其中， $n^{[l]}<em>{H} = \left\lfloor \dfrac{n^{[l-1]}</em>{H}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \right\rfloor$ ， $n^{[l]}<em>{W} = \left\lfloor \dfrac{n^{[l-1]}</em>{W}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \right\rfloor$ 。</p>
<h3 id="简单卷积网络示例："><a href="#简单卷积网络示例：" class="headerlink" title="简单卷积网络示例："></a>简单卷积网络示例：</h3><p>多层卷积构成卷积神经网络，下面是一个卷积神经网络的例子：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/15.jpg" alt=""></p>
<p>卷积网络层的类型：</p>
<ul>
<li>卷积层（Convolution），Conv；</li>
<li>池化层（Pooling），Pool；</li>
<li>全连接层（Fully connected）：Fc；</li>
</ul>
<h2 id="7-池化层"><a href="#7-池化层" class="headerlink" title="7. 池化层"></a>7. 池化层</h2><h3 id="最大池化（Max-pooling）："><a href="#最大池化（Max-pooling）：" class="headerlink" title="最大池化（Max pooling）："></a>最大池化（Max pooling）：</h3><p>最大池化是对前一层得到的特征图进行池化减小，仅由当前小区域内的最大值来代表最终池化后的值。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/16.jpg" alt=""></p>
<p>在最大池化中，有一组超参数需要进行调整，其中， f 表示池化的大小， s 表示步长。</p>
<ul>
<li>池化前： $n \times n$ ；</li>
<li>池化后： $\left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor\times \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor$ 。</li>
</ul>
<h3 id="平均池化（Average-pooling）："><a href="#平均池化（Average-pooling）：" class="headerlink" title="平均池化（Average pooling）："></a>平均池化（Average pooling）：</h3><p>平均池化与最大池化唯一不同的是其选取的是小区域内的均值来代表该区域内的值。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/17.jpg" alt=""></p>
<h3 id="Pooling-Summary："><a href="#Pooling-Summary：" class="headerlink" title="Pooling Summary："></a>Pooling Summary：</h3><p>池化层的超参数：</p>
<ul>
<li>f ：filter的大小；</li>
<li>s ：stride大小；</li>
<li>最大池化或者平均池化；</li>
<li>p ：padding，这里要注意，几乎很少使用。</li>
</ul>
<p>注意，池化层没有需要学习的参数。</p>
<h2 id="8-卷积神经网络示例"><a href="#8-卷积神经网络示例" class="headerlink" title="8. 卷积神经网络示例"></a>8. 卷积神经网络示例</h2><p>这里以 <strong>LeNet-5</strong> 为例，给出一个完整的卷积神经网络。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/18.jpg" alt=""></p>
<p>构建深度卷积的模式：</p>
<ul>
<li>随着网络的深入，提取的特征图片大小将会逐渐减小，但同时通道数量应随之增加；</li>
<li>Conv——Pool——Conv——Pool——Fc——Fc——Fc——softmax。</li>
</ul>
<h3 id="卷积神经网络的参数："><a href="#卷积神经网络的参数：" class="headerlink" title="卷积神经网络的参数："></a>卷积神经网络的参数：</h3><p><img src="/2018/03/04/卷积神经网络——卷积神经网络/19.jpg" alt=""></p>
<p>根据上表我们可以看出，对于卷积卷积神经网络的参数：</p>
<ul>
<li>在卷积层，仅有少量的参数；</li>
<li>在池化层，没有参数；</li>
<li>在全连接层，存在大量的参数。</li>
</ul>
<h2 id="9-使用卷积神经网络"><a href="#9-使用卷积神经网络" class="headerlink" title="9. 使用卷积神经网络"></a>9. 使用卷积神经网络</h2><h3 id="参数少的优势："><a href="#参数少的优势：" class="headerlink" title="参数少的优势："></a>参数少的优势：</h3><p>与普通的全连接神经网络相比，卷积神经网络的参数更少。如图中的例子，卷积神经网络仅有  6\times(5\times5+1)=156 个参数，而普通的全连接网络有 3072\times4704\approx 14M 个参数。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/20.jpg" alt=""></p>
<ul>
<li>参数共享：一个特征检测器（filter）对图片的一部分有用的同时也有可能对图片的另外一部分有用。</li>
<li>连接的稀疏性：在每一层中，每个输出值只取决于少量的输入。</li>
</ul>
<h3 id="训练卷积神经网络："><a href="#训练卷积神经网络：" class="headerlink" title="训练卷积神经网络："></a>训练卷积神经网络：</h3><p><img src="/2018/03/04/卷积神经网络——卷积神经网络/21.jpg" alt=""></p>
<p>我们将训练集输入到卷积神经网络中，对网络进行训练。利用梯度下降（Adam、momentum等优化算法）最小化代价函数来寻找网络的最优参数。</p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p>[1] deeplearning.ai 课件</p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/30800318" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/30800318</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/04/卷积神经网络——卷积神经网络/" data-id="cjeebbnza001t48wgyemhbu3f" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TensorFlow——Math" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/26/TensorFlow——Math/" class="article-date">
  <time datetime="2018-02-26T07:03:42.000Z" itemprop="datePublished">2018-02-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/26/TensorFlow——Math/">TensorFlow API——Math</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要对tf的一些数学操作方法进行汇总。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/02/26/TensorFlow——Math/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/02/26/TensorFlow——Math/" data-id="cjeebbnyg000n48wges7v7hbp" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Python-yield-及其实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/06/Python-yield-及其实现/" class="article-date">
  <time datetime="2018-02-06T12:15:15.000Z" itemprop="datePublished">2018-02-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python/">Python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/06/Python-yield-及其实现/">Python yield 及其实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Python-yield及其实现"><a href="#Python-yield及其实现" class="headerlink" title="Python yield及其实现"></a>Python yield及其实现</h1><p>刚开始接触python时，解接触到了 yield 关键字，在实际使用中，越来越觉得其用处的强大，遂感觉需整理一下自己的理解，做一个总结。yield 的功能类似于 return，但不同之处在于它返回的是生成器。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/02/06/Python-yield-及其实现/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/02/06/Python-yield-及其实现/" data-id="cjeebbny6000h48wg3zm0rzcj" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/yield-产生器-生成器/">yield 产生器 生成器</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TensorFlow-api-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/31/TensorFlow-api-1/" class="article-date">
  <time datetime="2018-01-31T15:24:08.000Z" itemprop="datePublished">2018-01-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/31/TensorFlow-api-1/">TensorFlow-api(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="TensorFlow-api-1-：tf-reduce-mean-这类函数"><a href="#TensorFlow-api-1-：tf-reduce-mean-这类函数" class="headerlink" title="TensorFlow-api(1)：tf.reduce_mean()这类函数"></a>TensorFlow-api(1)：tf.reduce_mean()这类函数</h1><p>在tensor的某一维度上，有一类求值的函数，如tf.reduce_max( )，tf.reduce_mean( )，tf.reduce_sum( )<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/31/TensorFlow-api-1/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/31/TensorFlow-api-1/" data-id="cjeebbnyg000l48wgjlw8eef7" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  
    <article id="post-简单有效的多标准中文分词" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/22/简单有效的多标准中文分词/" class="article-date">
  <time datetime="2018-01-22T07:40:02.000Z" itemprop="datePublished">2018-01-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/22/简单有效的多标准中文分词/">简单有效的多标准中文分词</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文介绍一种简洁优雅的多标准中文分词方案，可联合多个不同标准的语料库训练单个模型，同时输出多标准的分词结果。通过不同语料库之间的迁移学习提升模型的性能，在10个语料库上的联合试验结果优于绝大部分单独训练的模型。模型参数和超参数全部共享，复杂度不随语料库种类增长。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/22/简单有效的多标准中文分词/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/22/简单有效的多标准中文分词/" data-id="cjeebbo0r003o48wgwelzz8ti" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习总结/">机器学习总结</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-线性模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/19/线性模型/" class="article-date">
  <time datetime="2018-01-19T14:18:45.000Z" itemprop="datePublished">2018-01-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/19/线性模型/">线性模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="机器学习——线性模型"><a href="#机器学习——线性模型" class="headerlink" title="机器学习——线性模型"></a>机器学习——线性模型</h1><h2 id="广义线性模型（Generalized-Linear-Models）"><a href="#广义线性模型（Generalized-Linear-Models）" class="headerlink" title="广义线性模型（Generalized Linear Models）"></a>广义线性模型（Generalized Linear Models）</h2><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="均方误差最小化算法"><a href="#均方误差最小化算法" class="headerlink" title="均方误差最小化算法"></a>均方误差最小化算法</h3><p>基于均方误差最小化来进行模型求解的方法称为“最小二乘法（least square method）”。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小。</p>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>岭回归(英文名：ridge regression, Tikhonov regularization)是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。</p>
<h3 id="正则化算法"><a href="#正则化算法" class="headerlink" title="正则化算法"></a>正则化算法</h3><h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><h2 id="多元逻辑回归（Softmax-Regression）"><a href="#多元逻辑回归（Softmax-Regression）" class="headerlink" title="多元逻辑回归（Softmax Regression）"></a>多元逻辑回归（Softmax Regression）</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/19/线性模型/" data-id="cjeebbo0t003r48wgvx9ibauw" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习总结/">机器学习总结</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-结构化机器学习项目——机器学习策略-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/15/结构化机器学习项目——机器学习策略-2/" class="article-date">
  <time datetime="2018-01-15T04:35:55.000Z" itemprop="datePublished">2018-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/15/结构化机器学习项目——机器学习策略-2/">结构化机器学习项目——机器学习策略(2)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习策略-2"><a href="#机器学习策略-2" class="headerlink" title="机器学习策略(2)"></a>机器学习策略(2)</h1><h2 id="进行误差分析"><a href="#进行误差分析" class="headerlink" title="进行误差分析"></a>进行误差分析</h2><p>当我们在训练一个模型的时候，如一个猫和狗分类模型，最终得到了 90\% 的精确度，即有 10\% 的错误率。所以我们需要对模型做相应调整，才能更好地提升分类的精度。但是，这需要我们花费很长时间才能得到结果，可是这样做是否值得？<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-2/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/15/结构化机器学习项目——机器学习策略-2/" data-id="cjeebbo0y003y48wgr9lexq9m" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-结构化机器学习项目——机器学习策略-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/15/结构化机器学习项目——机器学习策略-1/" class="article-date">
  <time datetime="2018-01-15T04:35:49.000Z" itemprop="datePublished">2018-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/15/结构化机器学习项目——机器学习策略-1/">结构化机器学习项目——机器学习策略(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习策略-1"><a href="#机器学习策略-1" class="headerlink" title="机器学习策略(1)"></a>机器学习策略(1)</h1><h2 id="为什么是ML策略"><a href="#为什么是ML策略" class="headerlink" title="为什么是ML策略"></a>为什么是ML策略</h2><p>假如我们在构建一个喵咪分类器，数据集就是上面几个图，训练之后准确率达到90%。虽然看起来挺高的，但是这显然并不具一般性，因为数据集太少了。那么此时可以想到的ML策略有哪些呢？<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-1/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/15/结构化机器学习项目——机器学习策略-1/" data-id="cjeebbo0w003v48wgluut5f10" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——超参数调试、Batch正则化和程序框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" class="article-date">
  <time datetime="2018-01-14T02:39:49.000Z" itemprop="datePublished">2018-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/">改善深层神经网络——超参数调试、Batch正则化和程序框架</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="超参数调试、Batch正则化和程序框架"><a href="#超参数调试、Batch正则化和程序框架" class="headerlink" title="超参数调试、Batch正则化和程序框架"></a>超参数调试、Batch正则化和程序框架</h1><h2 id="超参数的调试处理"><a href="#超参数的调试处理" class="headerlink" title="超参数的调试处理"></a>超参数的调试处理</h2><p>在机器学习领域，超参数比较少，我们之前利用设置网格点的方式来调试超参数；<br>但在深度学习领域，超参数较多，不再是设置规则的网格点，而是随机选择点进行调试。这样做是因为，在我们处理问题的时候，无法知道哪个超参数更为重要，随机的方式测试超参数点的性能更为合理，可以探究超参数的潜在价值。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" data-id="cjeebbnzk002f48wg86vo7ms1" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next&raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/yespon" target="_blank" title="Github"></a>
      
      
            <a class="weibo" aria-hidden="true"  href="http://weibo.com/yespon" target="_blank" title="微博"></a>
      
      
              <a class="zhihu" aria-hidden="true"  href="http://www.zhihu.com/people/yespon" target="_blank" title="知乎"></a>
      
      
            <a class="email" aria-hidden="true"  href="mailto:yespon@qq.com" target="_blank" title="邮箱"></a>
      
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title categories">Categories</h3>
    <div class="widget" id="categories">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Framework-Tools/">Framework&Tools</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器技术/">服务器技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">26</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/">架构&设计</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/经典文摘/">经典文摘</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNN-AlexNet/" style="font-size: 14px; color: #00f">CNN AlexNet</a> <a href="/tags/CUDA-GPUs/" style="font-size: 14px; color: #00f">CUDA GPUs</a> <a href="/tags/LDAP/" style="font-size: 14px; color: #00f">LDAP</a> <a href="/tags/MQ/" style="font-size: 19.5px; color: #7741f7">MQ</a> <a href="/tags/Nginx/" style="font-size: 14px; color: #00f">Nginx</a> <a href="/tags/Sticky/" style="font-size: 14px; color: #00f">Sticky</a> <a href="/tags/TensorFlow/" style="font-size: 16.75px; color: #3c21fb">TensorFlow</a> <a href="/tags/Tensorflow/" style="font-size: 22.25px; color: #b362f2">Tensorflow</a> <a href="/tags/UUID/" style="font-size: 14px; color: #00f">UUID</a> <a href="/tags/decorator/" style="font-size: 14px; color: #00f">decorator</a> <a href="/tags/deeplearning-ai/" style="font-size: 25px; color: #ee82ee">deeplearning.ai</a> <a href="/tags/kNN-算法/" style="font-size: 16.75px; color: #3c21fb">kNN 算法</a> <a href="/tags/pandas-read-csv/" style="font-size: 14px; color: #00f">pandas read_csv</a> <a href="/tags/quarts/" style="font-size: 14px; color: #00f">quarts</a> <a href="/tags/schedule/" style="font-size: 14px; color: #00f">schedule</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #00f">tensorflow</a> <a href="/tags/yield-产生器-生成器/" style="font-size: 14px; color: #00f">yield 产生器 生成器</a> <a href="/tags/似然估计-likehood/" style="font-size: 14px; color: #00f">似然估计 likehood</a> <a href="/tags/分布式/" style="font-size: 14px; color: #00f">分布式</a> <a href="/tags/反向代理/" style="font-size: 14px; color: #00f">反向代理</a> <a href="/tags/唯一性ID/" style="font-size: 14px; color: #00f">唯一性ID</a> <a href="/tags/性能指标/" style="font-size: 14px; color: #00f">性能指标</a> <a href="/tags/机器学习总结/" style="font-size: 16.75px; color: #3c21fb">机器学习总结</a> <a href="/tags/消息中间件/" style="font-size: 19.5px; color: #7741f7">消息中间件</a> <a href="/tags/神经网络-NN/" style="font-size: 14px; color: #00f">神经网络 NN</a> <a href="/tags/装饰器/" style="font-size: 14px; color: #00f">装饰器</a> <a href="/tags/集群/" style="font-size: 14px; color: #00f">集群</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/05/TensorFlow基本概念/">TensorFlow基本概念</a>
          </li>
        
          <li>
            <a href="/2018/03/04/卷积神经网络——卷积神经网络/">卷积神经网络——卷积神经网络</a>
          </li>
        
          <li>
            <a href="/2018/02/26/TensorFlow——Math/">TensorFlow API——Math</a>
          </li>
        
          <li>
            <a href="/2018/02/06/Python-yield-及其实现/">Python yield 及其实现</a>
          </li>
        
          <li>
            <a href="/2018/01/31/TensorFlow-api-1/">TensorFlow-api(1)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="http://yespon.github.io">yespon&#39;s blog</a>
            </li>
            
        </ul>
    </div>
</div>

  
    <!--微信公众号二维码-->

  <div class="widget-wrap">
    <h3 class="follow-title ">WeChat</h3>
    <div class="widget wechat-widget">
        <img src="/images/wechat_yespon.jpg" alt="扫码关注" width="250"/>
    </div>
  </div>


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 Yespon&nbsp;|&nbsp;
      Theme by <a href="https://github.com/yespon/hexo-theme-yespon/" target="_blank">Yespon</a>
    </div>
     <div id="footer-right">
      Contact&nbsp;|&nbsp;yespon#qq.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/categories" class="mobile-nav-link">Category</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script> 
  <script>
  var gitment = new Gitment({
    // id: '页面 ID', // 可选。默认为 location.href
    owner: 'yespon',
    repo: 'yespon.github.io',
    oauth: {
    client_id: '4ab181ded22ebacbab72',
    client_secret: 'c3cd3df382f34a5685a1608234223423248250f7',
    }
  })
  gitment.render(document.getElementById("gitment_comments"))
</script>


<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>