<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Life Designer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Life Designer, design by oneself!">
<meta property="og:type" content="website">
<meta property="og:title" content="Life Designer">
<meta property="og:url" content="http://yespon.github.io/index.html">
<meta property="og:site_name" content="Life Designer">
<meta property="og:description" content="Life Designer, design by oneself!">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Designer">
<meta name="twitter:description" content="Life Designer, design by oneself!">
  
    <link rel="alternate" href="/atom.xml" title="Life Designer" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yespon.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/categories">Category</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Designer</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Life Designer, design by oneself!</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-面试总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/29/面试总结/" class="article-date">
  <time datetime="2018-03-29T08:11:49.000Z" itemprop="datePublished">2018-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/29/面试总结/">面试总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="算法面试总结"><a href="#算法面试总结" class="headerlink" title="算法面试总结"></a>算法面试总结</h1><h2 id="机器学习部分"><a href="#机器学习部分" class="headerlink" title="机器学习部分"></a>机器学习部分</h2><h3 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h3><h4 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h4><h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><h4 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h4><h3 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h3><h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h4><h3 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><h4 id="间隔与支持向量"><a href="#间隔与支持向量" class="headerlink" title="间隔与支持向量"></a>间隔与支持向量</h4><h4 id="线性可分与硬间隔"><a href="#线性可分与硬间隔" class="headerlink" title="线性可分与硬间隔"></a>线性可分与硬间隔</h4><h4 id="线性SVM和软间隔"><a href="#线性SVM和软间隔" class="headerlink" title="线性SVM和软间隔"></a>线性SVM和软间隔</h4><h4 id="非线性可分SVM与核函数"><a href="#非线性可分SVM与核函数" class="headerlink" title="非线性可分SVM与核函数"></a>非线性可分SVM与核函数</h4><h4 id="序列最小最优化算法（SMO）"><a href="#序列最小最优化算法（SMO）" class="headerlink" title="序列最小最优化算法（SMO）"></a>序列最小最优化算法（SMO）</h4><h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><h4 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h4><h4 id="ID3、C4-5、CART"><a href="#ID3、C4-5、CART" class="headerlink" title="ID3、C4.5、CART"></a>ID3、C4.5、CART</h4><h4 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h4><h4 id="连续与缺失值"><a href="#连续与缺失值" class="headerlink" title="连续与缺失值"></a>连续与缺失值</h4><h3 id="集成学习（Ensemble）"><a href="#集成学习（Ensemble）" class="headerlink" title="集成学习（Ensemble）"></a>集成学习（Ensemble）</h3><h4 id="Bagging与随机森林"><a href="#Bagging与随机森林" class="headerlink" title="Bagging与随机森林"></a>Bagging与随机森林</h4><h5 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h5><h5 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h5><h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h4><h5 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h5><h5 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h5><h5 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h5>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/29/面试总结/" data-id="cjfg68vnp004b04wgk8eq2p7e" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  
    <article id="post-卷积神经网络——目标检测" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/22/卷积神经网络——目标检测/" class="article-date">
  <time datetime="2018-03-22T09:22:38.000Z" itemprop="datePublished">2018-03-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/22/卷积神经网络——目标检测/">卷积神经网络——目标检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="1-目标定位和特征点检测"><a href="#1-目标定位和特征点检测" class="headerlink" title="1. 目标定位和特征点检测"></a>1. 目标定位和特征点检测</h2><h3 id="图片检测问题："><a href="#图片检测问题：" class="headerlink" title="图片检测问题："></a>图片检测问题：</h3><ul>
<li>分类问题：判断图中是否为汽车；</li>
<li>目标定位：判断是否为汽车，并确定具体位置；</li>
<li>目标检测：检测不同物体并定位。</li>
</ul>
<p><img src="/2018/03/22/卷积神经网络——目标检测/1.jpg" alt=""></p>
<h3 id="目标分类和定位："><a href="#目标分类和定位：" class="headerlink" title="目标分类和定位："></a>目标分类和定位：</h3><p>对于目标定位问题，我们卷积神经网络模型结构可能如下：</p>
<p><img src="/2018/03/22/卷积神经网络——目标检测/2.jpg" alt=""></p>
<p>输出：包含图片中存在的对象及定位框</p>
<ul>
<li>行人，0 or 1；</li>
<li>汽车，0 or 1；</li>
<li>摩托车，0 or 1；</li>
<li>图片背景，0 or 1；</li>
<li>定位框： $b<em>{x}$、$b</em>{y}$、$b<em>{h}$、$b</em>{w}$</li>
</ul>
<p>其中， $b<em>{x}、b</em>{y}$ 表示汽车中点， $b<em>{h}$、$b</em>{w}$ 分别表示定位框的高和宽。以图片左上角为(0,0)，以右下角为(1,1)，这些数字均为位置或长度所在图片的比例大小。</p>
<h3 id="目标标签-y："><a href="#目标标签-y：" class="headerlink" title="目标标签 y："></a>目标标签 y：</h3><p>$$y = \left[ \begin{array}{l} P<em>{c}\\ b</em>{x}\\ b<em>{y}\\ b</em>{h}\\ b<em>{w}\\ c</em>{1}\\ c<em>{2}\\ c</em>{3} \end{array} \right]\left| \begin{array}{l} 是否含有对象，0 or 1\ \ \ \ \ 是否有行人，0 or 1\ 是否有汽车，0 or 1\ 是否有摩托，0 or 1 \end{array} \right$$.</p>
<ul>
<li>当 P_{c}=1 时，表示图片中存在物体；</li>
<li>当 P_{c}=0 时，表示图片中不存在物体，那么此时，输出 y 的其他值为多少均没有意义，也不会参与损失函数的计算:</li>
</ul>
<p>$$y = \left[ \begin{array}{l} 0\ ?\ ?\ …\ ? \end{array} \right]$$</p>
<h3 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h3><p>如果采用平方误差形式的损失函数：</p>
<ul>
<li><p>当 $P<em>{c}=1$ 时：$L(\hat y,y)=(\hat y</em>{1}-y<em>{1})^{2}+(\hat y</em>{2}-y<em>{2})^{2}+\cdots+(\hat y</em>{8}-y_{8})^{2}$</p>
<pre><code>此时，我们需要关注神经网络对所有输出值的准确度；
</code></pre></li>
<li><p>当 P<em>{c}=0 时：L(\hat y,y)=(\hat y</em>{1}-y_{1})^{2} </p>
<pre><code>此时，我们只关注神经网络对背景值的准确度。
</code></pre></li>
</ul>
<p>当然在实际的目标定位应用中，我们可以使用更好的方式是：</p>
<p>对 c<em>{1}、c</em>{2}、c_{3} 和softmax使用对数似然损失函数；<br>对边界框的四个值应用平方误差或者类似的方法；<br>对 P_c 应用logistic regression损失函数，或者平方预测误差。</p>
<p>特征点检测：</p>
<p>由前面的目标定位问题，我们可以知道，神经网络可以通过输出图片上特征点的坐标（x,y），来实现对目标特征的识别和定位标记。</p>
<p>如对于人脸表情识别的问题中，我们通过标定训练数据集中特征点的位置信息，来对人脸进行不同位置不同特征的定位和标记。AR的应用就是基于人脸表情识别来设计的，如脸部扭曲、增加头部配饰等。</p>
<p>在人体姿态检测中，同样可以通过对人体不同的特征位置关键点的标注，来记录人体的姿态。</p>
<ol>
<li>目标检测</li>
</ol>
<p>目标检测采用的是基于滑动窗口的检测算法。</p>
<p>训练模型：</p>
<p>训练集X：将有汽车的图片进行适当的剪切，剪切成整张几乎都被汽车占据的小图或者没有汽车的小图；<br>训练集Y：对X中的图片进行标注，有汽车的标注1，没有汽车的标注0。</p>
<p>滑动窗口目标检测：</p>
<p>利用滑动窗口在实际图片中实现目标检测。</p>
<p>首先选定一个特定大小的窗口，将窗口内的图片输入到模型中进行预测；<br>以固定步幅滑动该窗口，遍历图像的每个区域，对窗内的各个小图不断输入模型进行预测；<br>继续选取一个更大的窗口，再次遍历图像的每个区域，对区域内是否有车进行预测；<br>遍历整个图像，可以保证在每个位置都能检测到是否有车。<br>缺点：计算成本巨大，每个窗口的小图都要进行卷积运算，（但在神经网络兴起之前，使用的是线性分类器，所以滑动窗口算法的计算成本较低）。</p>
<p>卷积层替代全连接层：</p>
<p>对于卷积网络中全连接层，我们可以利用 1\times1 大小卷积核的卷积层来替代。</p>
<p>在上一周课程中，吴恩达老师讲授过 1\times1 的卷积核相当于在一个三维图像的切片上应用了一个全连接的神经网络。同样，全连接层也可以由 1\times1 大小卷积核的卷积层来替代。需注意卷积核的个数与隐层神经元个数相同。</p>
<p>滑动窗口的卷积实现：</p>
<p>在我们实现了以卷积层替代全部的全连接层以后，在该基础上进行滑动窗口在卷积层上的操作。下面以一个小的图片为例：</p>
<p>我们以上面训练好的模型，输入一个 16\times16\times3 大小的整幅图片，图中蓝色部分代表滑动窗口的大小。我们以2为大小的步幅滑动窗口，分别与卷积核进行卷积运算，最后得到4幅 10\times10\times16 大小的特征图，然而因为在滑动窗口的操作时，输入部分有大量的重叠，也就是有很多重复的运算，导致在下一层中的特征图值也存在大量的重叠，所以最后得到的第二层激活值（特征图）构成一副 12\times12\times16 大小的特征图。对于后面的池化层和全连接层也是同样的过程。</p>
<p>那么由此可知，滑动窗口在整幅图片上进行滑动卷积的操作过程，就等同于在该图片上直接进行卷积运算的过程。所以卷积层实现滑动窗口的这个过程，我们不需要把输入图片分割成四个子集分别执行前向传播，而是把他们作为一张图片输入到卷积神经网络中进行计算，其中的重叠部分（公共区域）可以共享大量的计算。</p>
<p>汽车目标检测：</p>
<p>依据上面的方法，我们将整张图片输入到训练好的卷积神经网络中。无需再利用滑动窗口分割图片，只需一次前向传播，我们就可以同时得到所有图片子集的预测值。</p>
<p>利用卷积的方式实现滑动窗口算法的方法，提高了整体的计算效率。</p>
<ol>
<li>Bounding Box 预测</li>
</ol>
<p>前面一节的卷积方式实现的滑动窗口算法，使得在预测时计算的效率大大提高。但是其存在的问题是：不能输出最精准的边界框（Bounding Box）。</p>
<p>在滑动窗口算法中，我们取的一些离散的图片子集的位置，在这种情况下，有可能我们没有得到一个能够完美匹配汽车位置的窗口，也有可能真实汽车的边界框为一个长方形。所以我们需要寻找更加精确的边界框。</p>
<p>YOLO：</p>
<p>YOLO算法可以使得滑动窗口算法寻找到更加精准的边界框。</p>
<p>在整幅图片上加上较为精细的网格，将图片分割成 n\times n 个小的图片；<br>采用图像分类和定位算法，分别应用在图像的 n\times n 个格子中。<br>定义训练标签：（对于每个网格，定义如前面的向量 y<em>{i} ）<br>y</em>{i} = \left[ \begin{array}{l} P<em>{c}\ b</em>{x}\ b<em>{y}\ b</em>{h}\ b<em>{w}\ c</em>{1}\ c<em>{2}\ c</em>{3} \end{array} \right] </p>
<pre><code>对于不同的网格 i 有不同的标签向量 y_{i} 。
</code></pre><p>将 n\times n 个格子标签合并在一起，最终的目标输出Y的大小为： n\times n\times 8 （这里8是因为例子中的目标值有8个）。<br>通过这样的训练集训练得到目标探测的卷积网络模型。我们利用训练好的模型，将与模型输入相同大小的图片输入到训练好的网络中，得到大小为 n\times n\times 8 的预测输出。通过观察 n\times n 不同位置的输出值，我们就能知道这些位置中是否存在目标物体，然后也能由存在物体的输出向量得到目标物体的更加精准的边界框。</p>
<p>YOLO notation：</p>
<p>将对象分配到一个格子的过程是：观察对象的中点，将该对象分配到其中点所在的格子中，（即使对象横跨多个格子，也只分配到中点所在的格子中，其他格子记为无该对象，即标记为“0”）；<br>YOLO显式地输出边界框，使得其可以具有任意宽高比，并且能输出更精确的坐标，不受滑动窗口算法滑动步幅大小的限制；<br>YOLO是一次卷积实现，并不是在 n\times n 网格上进行 n^{2} 次运算，而是单次卷积实现，算法实现效率高，运行速度快，可以实现实时识别。</p>
<p>bounding boxes 细节：</p>
<p>利用YOLO算法实现目标探测的时候，对于存在目标对象的网格中，定义训练标签Y的时候，边界框的指定参数的不同对其预测精度有很大的影响。这里给出一个较为合理的约定：（其他参数指定方式可阅读论文）</p>
<p>对于每个网格，以左上角为(0,0)，以右下角为(1,1)；<br>中点 b<em>{x}、b</em>{y} 表示坐标值，在0~1之间；<br>宽高 b<em>{h}、b</em>{w} 表示比例值，存在&gt;1的情况。</p>
<ol>
<li>交并比（Intersection-over-Union）</li>
</ol>
<p>交并比函数用来评价目标检测算法是否运作良好。</p>
<p>对于理想的边界框和目标探测算法预测得到的边界框，交并比函数计算两个边界框交集和并集之比。</p>
<p>\rm IoU = \dfrac{交集面积}{并集面积} </p>
<p>一般在目标检测任务中，约定如果 IoU\geqslant0.5 ，那么就说明检测正确。当然标准越大，则对目标检测算法越严格。得到的IoU值越大越好。</p>
<ol>
<li>非最大值抑制（non-max suppression，NMS）</li>
</ol>
<p>对于我们前面提到的目标检测算法，可能会对同一个对象做出多次的检测，非最大值抑制可以确保我们的算法对每个对象只检测一次。</p>
<p>多网格检测同一物体：</p>
<p>对于汽车目标检测的例子中，我们将图片分成很多精细的格子。最终预测输出的结果中，可能会有相邻的多个格子里均检测出都具有同一个对象。</p>
<p>NMS算法思想：</p>
<p>在对 n\times n 个网格进行目标检测算法后，每个网格输出的 P<em>{c} 为一个0~1的值，表示有车的概率大小。其中会有多个网格内存在高概率；<br>得到对同一个对象的多次检测，也就是在一个对象上有多个具有重叠的不同的边界框；<br>非最大值抑制对多种检测结果进行清理：选取最大 P</em>{c} 的边界框，对所有其他与该边界框具有高交并比或高重叠的边界框进行抑制；<br>逐一审视剩下的边界框，寻找最高的 P_{c} 值边界框，重复上面的步骤。<br>非最大值抑制，也就是说抑制那些不是最大值，却比较接近最大值的边界框。</p>
<p>NMS算法：</p>
<p>以单个对象检测为例：</p>
<p>对于图片每个网格预测输出矩阵： y<em>{i} = \left[ \begin{array}{l} P</em>{c}\ b<em>{x}\ b</em>{y}\ b<em>{h}\ b</em>{w} \end{array} \right] ，其中 P<em>{c} 表示有对象的概率；<br>抛弃 P</em>{c}\leqslant0.6 的边界框，也就是低概率的情况；<br>对剩余的边界框（while）：</p>
<pre><code>- 选取最大 P_{c} 值的边界框，作为预测输出边界框；

- 抛弃和选取的边界框 IoU\geqslant0.5 的剩余的边界框。
</code></pre><p>对于多对象检测，输出标签中就会有多个分量。正确的做法是：对每个输出类别分别独立进行一次非最大值抑制。</p>
<ol>
<li>Anchor box</li>
</ol>
<p>通过上面的各种方法，目前我们的目标检测算法在每个格子上只能检测出一个对象。使用Anchor box可以同时检测出多个对象。</p>
<p>重叠目标：</p>
<p>对于重叠的目标，这些目标的中点有可能会落在同一个网格中，对于我们之前定义的输出： y<em>{i} = \left[ \begin{array}{l} P</em>{c}\ b<em>{x}\ b</em>{y}\ b<em>{h}\ b</em>{w}\ c<em>{1}\ c</em>{2}\ c_{3} \end{array} \right] ，只能得到一个目标的输出。</p>
<p>而Anchor box 则是预先定义多个不同形状的Anchor box，我们需要把预测目标对应地和各个Anchor box 关联起来，所以我们重新定义目标向量：</p>
<p>y<em>{i} = \left[ P</em>{c}\ b<em>{x}\ b</em>{y}\ b<em>{h}\ b</em>{w}\ c<em>{1}\ c</em>{2}\ c<em>{3}\ P</em>{c}\ b<em>{x}\ b</em>{y}\ b<em>{h}\ b</em>{w}\ c<em>{1}\ c</em>{2}\ c_{3}\cdots\right] </p>
<p>用这样的多目标向量分别对应不同的Anchor box，从而检测出多个重叠的目标。</p>
<p>不使用Anchor box：训练图片中的每个对象，根据对象的中点，分配到对应的格子中。输出大小（例如8）： n\times n\times 8 ；<br>使用Anchor box：训练图片的每个对象，根据对象的中点，分配到对应的格子中，同时还分配到一个和对象形状的IoU最高的Anchor box 中。输出大小（例如两个Anchor box）： n\times n\times 16 。</p>
<p>例子：</p>
<p>如下面的图片，里面有行人和汽车，我们为其分配两个Anchor box。对于行人形状更像Anchor box 1，汽车形状更像Anchor box 2，所以我们将人和汽车分配到不同的输出位置。</p>
<p>如果格子中只有汽车的时候，我们使用了两个Anchor box，那么此时我们的目标向量就成为：</p>
<p>y<em>{i} = \left[ 0\ ?\ ?\ ?\ ?\ ?\ ?\ ?\ 1\ b</em>{x}\ b<em>{y}\ b</em>{h}\ b_{w}\ 0\ 1\ 0\right] </p>
<p>其中，“？”代表的是该位置是什么样的参数我们都不关心。</p>
<p>难点问题：</p>
<p>如果我们使用了两个Anchor box，但是同一个格子中却有三个对象的情况，此时只能用一些额外的手段来处理；<br>同一个格子中存在两个对象，但它们的Anchor box 形状相同，此时也需要引入一些专门处理该情况的手段。<br>但是以上的两种问题出现的可能性不会很大，对目标检测算法不会带来很大的影响。</p>
<p>Anchor box 的选择：</p>
<p>一般人工指定Anchor box 的形状，选择5~10个以覆盖到多种不同的形状，可以涵盖我们想要检测的对象的形状；<br>高级方法：K-means 算法：将不同对象形状进行聚类，用聚类后的结果来选择一组最具代表性的Anchor box，以此来代表我们想要检测对象的形状。</p>
<ol>
<li>YOLO算法目标检测</li>
</ol>
<p>假设我们要在图片中检测三种目标：行人、汽车和摩托车，同时使用两种不同的Anchor box。</p>
<p>训练集：</p>
<p>输入X：同样大小的完整图片；<br>目标Y：使用 3\times3 网格划分，输出大小 3\times3\times2\times8 ，或者 3\times3\times16<br>对不同格子中的小图，定义目标输出向量Y。</p>
<p>模型预测：</p>
<p>输入与训练集中相同大小的图片，同时得到每个格子中不同的输出结果： 3\times3\times2\times8 。</p>
<p>运行非最大值抑制（NMS）：</p>
<p>假设使用了2个Anchor box，那么对于每一个网格，我们都会得到预测输出的2个bounding boxes，其中一个 P<em>{c} 比较高；<br>抛弃概率 P</em>{c} 值低的预测bounding boxes；</p>
<p>对每个对象（如行人、汽车、摩托车）分别使用NMS算法得到最终的预测边界框。</p>
<ol>
<li>候选区域（region proposals）</li>
</ol>
<p>R-CNN：</p>
<p>R-CNN（Regions with convolutional networks），会在我们的图片中选出一些目标的候选区域，从而避免了传统滑动窗口在大量无对象区域的无用运算。</p>
<p>所以在使用了R-CNN后，我们不会再针对每个滑动窗口运算检测算法，而是只选择一些候选区域的窗口，在少数的窗口上运行卷积网络。</p>
<p>具体实现：运用图像分割算法，将图片分割成许多不同颜色的色块，然后在这些色块上放置窗口，将窗口中的内容输入网络，从而减小需要处理的窗口数量。</p>
<p>更快的算法：</p>
<p>R-CNN：给出候选区域，不使用滑动窗口，对每个候选区域进行分类识别，输出对象 标签 和 bounding box，从而在确实存在对象的区域得到更精确的边界框，但速度慢；<br>Fast R-CNN：给出候选区域，使用滑动窗口的卷积实现去分类所有的候选区域，但得到候选区的聚类步骤仍然非常慢；<br>Faster R-CNN：使用卷积网络给出候选区域。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/22/卷积神经网络——目标检测/" data-id="cjfg68vml002i04wgtk2zoriu" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TF-IDF与余弦相似性" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/16/TF-IDF与余弦相似性/" class="article-date">
  <time datetime="2018-03-16T03:35:21.000Z" itemprop="datePublished">2018-03-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/16/TF-IDF与余弦相似性/">TF-IDF与余弦相似性</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><p>TF指Term frequecy,代表词频,IDF代表inverse document frequency,叫做逆文档频率。</p>
<p>这个算法可以用来提取文档的关键词，首先一般认为在文章中出现次数较多的词是关键词，词频就代表了这一项，结果你肯定猜到了，出现次数最多的词是—-“的”、”是”、”在”—-这一类最常用的词。它们叫做”停用词”（stop words），表示对找到结果毫无帮助、必须过滤掉的词。比如过滤之后再统计词频出现了中国，蜜蜂，养殖且三个词的词频几乎一致，但是”中国”是很常见的词，相对而言，”蜜蜂”和”养殖”不那么常见。<br>所以，我们需要一个重要性调整系数，衡量一个词是不是常见词。如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性，正是我们所需要的关键词。<br>显然，“中国”这个词出现在其他文章的概率比其他两个词要高不少，因此我们应该认为后两个词更能表现文章的主题，用统计学语言表达，就是在词频的基础上，要对每个词分配一个”重要性”权重。最常见的词（”的”、”是”、”在”）给予最小的权重，较常见的词（”中国”）给予较小的权重，较少见的词（”蜜蜂”、”养殖”）给予较大的权重。这个权重叫做”逆文档频率”（Inverse Document Frequency，缩写为IDF），它的大小与一个词的常见程度成反比。计算该值需要一个语料库，如果一个词在语料库中出现的概率越小，那么该词的IDF应该越大，一般来说TF计算公式为</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/1.png" alt=""></p>
<p>考虑到文章有长短之分，为了便于不同文章的比较，进行”词频”标准化。</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/2.png" alt=""></p>
<p>或者</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/3.png" alt=""></p>
<p>IDF计算公式为：</p>
<p>这里，需要一个语料库（corpus），用来模拟语言的使用环境。</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/4.png" alt=""></p>
<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）（平滑）。</p>
<p>将两者乘乘起来就得到了词的TF-IDF。</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/5.png" alt=""></p>
<p>TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以”词频”衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，可以针对不同位置赋予不同的权重进行修正（比如，对全文的第一段和每一段的第一句话，给予较大的权重），注意这些修正之所以是有效的，正是因为人观测过了大量的信息，因此建议了一个先验估计，人将这个先验估计融合到了算法里面，所以使算法更加的有效。</p>
<h2 id="余弦距离是什么，有哪些作用？"><a href="#余弦距离是什么，有哪些作用？" class="headerlink" title="余弦距离是什么，有哪些作用？"></a>余弦距离是什么，有哪些作用？</h2><p>余弦距离是两个向量的距离的一种度量方式，其值在-1~1之间，如果为1表示两个向量同相，0表示两个向量正交，-1表示两个向量反向。两条线段之间形成一个夹角，如果夹角为0度，意味着方向相同、线段重合；如果夹角为90度，意味着形成直角，方向完全不相似；如果夹角为180度，意味着方向正好相反。因此，我们可以<strong>通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。</strong></p>
<h3 id="余弦计算公式"><a href="#余弦计算公式" class="headerlink" title="余弦计算公式"></a>余弦计算公式</h3><p>假定a向量是[x1, y1]，b向量是[x2, y2]，那么可以将余弦定理改写成下面的形式：</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/6.png" alt=""></p>
<p>数学家已经证明，余弦的这种计算方法对n维向量也成立。假定A和B是两个n维向量，A是 [A1, A2, …, An] ，B是 [B1, B2, …, Bn] ，则A与B的夹角θ的余弦等于：</p>
<p><img src="/2018/03/16/TF-IDF与余弦相似性/7.png" alt=""></p>
<p>由此，我们就得到了”找出相似文章”的一种算法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">　　（1）使用TF-IDF算法，找出两篇文章的关键词；</div><div class="line">　　（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；</div><div class="line">　　（3）生成两篇文章各自的词频向量；</div><div class="line">　　（4）计算两个向量的余弦相似度，值越大就表示越相似。</div></pre></td></tr></table></figure>
<p>“余弦相似度”是一种非常有用的算法，只要是计算两个向量的相似程度，都可以采用它。</p>
<p>参考：</p>
<ol>
<li><p><a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2013/03/tf-idf.html</a></p>
</li>
<li><p>统计学习方法(李航)</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/16/TF-IDF与余弦相似性/" data-id="cjfg68vln000r04wg1mbbmmww" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TF-IDF/">TF-IDF</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/余弦相似度/">余弦相似度</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-ML—模型评估方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/14/ML—模型评估方法/" class="article-date">
  <time datetime="2018-03-14T07:58:12.000Z" itemprop="datePublished">2018-03-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/14/ML—模型评估方法/">ML—模型评估方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="ML—模型评估方法"><a href="#ML—模型评估方法" class="headerlink" title="ML—模型评估方法"></a>ML—模型评估方法</h1><h2 id="1-留出法"><a href="#1-留出法" class="headerlink" title="1. 留出法"></a>1. 留出法</h2><p>“留出法”直接将数据集 D 划分成两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即 $D=S \ T, S \ T = \$。在 S上训练处模型后，用T来评估测试误差，作为对泛化误差的估计。<br>Notation：</p>
<h2 id="2-交叉验证法"><a href="#2-交叉验证法" class="headerlink" title="2. 交叉验证法"></a>2. 交叉验证法</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/14/ML—模型评估方法/" data-id="cjfg68vkq000604wg7j8f3eat" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/模型评估/">模型评估</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-sklearn-preprocessing-数据预处理（OneHotEncoder）" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/13/sklearn-preprocessing-数据预处理（OneHotEncoder）/" class="article-date">
  <time datetime="2018-03-13T06:12:57.000Z" itemprop="datePublished">2018-03-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/13/sklearn-preprocessing-数据预处理（OneHotEncoder）/">sklearn preprocessing 数据预处理（OneHotEncoder）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-one-hot编码的由来"><a href="#1-one-hot编码的由来" class="headerlink" title="1. one-hot编码的由来"></a>1. one-hot编码的由来</h2><p>在实际的应用场景中，有非常多的特征不是连续的数值变量，而是某一些离散的类别。比如在广告系统中，用户的性别，用户的地址，用户的兴趣爱好等等一系列特征，都是一些分类值。这些特征一般都无法直接应用在需要进行数值型计算的算法里，比如CTR预估中最常用的LR。那针对这种情况最简单的处理方式是将不同的类别映射为一个整数，比如男性是0号特征，女性为1号特征。这种方式最大的优点就是简单粗暴，实现简单。那最大的问题就是在这种处理方式中，各种类别的特征都被看成是有序的，这显然是非常不符合实际场景的。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/03/13/sklearn-preprocessing-数据预处理（OneHotEncoder）/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/13/sklearn-preprocessing-数据预处理（OneHotEncoder）/" data-id="cjfg68vmb002104wgce23affp" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sklearn/">sklearn</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TensorFlow基本概念" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/05/TensorFlow基本概念/" class="article-date">
  <time datetime="2018-03-05T07:07:26.000Z" itemprop="datePublished">2018-03-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/05/TensorFlow基本概念/">TensorFlow基本概念</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="TensorFlow基本概念"><a href="#TensorFlow基本概念" class="headerlink" title="TensorFlow基本概念"></a>TensorFlow基本概念</h1><p>开始使用 TensorFlow 时，我们需要了解下其基本组成元素：</p>
<!--nore-->
<ul>
<li><p>使用<strong>计算图（graph )</strong> 定义计算任务</p>
</li>
<li><p>在被称之为<strong>会话 (Session)</strong> 的<strong>上下文 (context)</strong> 中，运行<strong>计算图（graph）</strong></p>
</li>
<li><p>使用<strong>张量（tensor）</strong>表示数据</p>
</li>
<li><p>通过<strong>变量（Variable）</strong>维护状态，对应的还有<strong>常量（constant）</strong></p>
</li>
<li><p>使用<strong>注入（feed）</strong>（喂数据）为任意<strong>操作</strong>(arbitrary <strong>operation</strong>) 赋值，使用<strong>取回（fetch）</strong>从任意操作中获取数据</p>
</li>
</ul>
<p>TensorFlow是一个编程系统，结合下图，我们从基本元素开始说起。</p>
<p><img src="/2018/03/05/TensorFlow基本概念/1.gif" alt=""></p>
<h2 id="1-张量-Tensor"><a href="#1-张量-Tensor" class="headerlink" title="1. 张量(Tensor)"></a>1. 张量(Tensor)</h2><p>名字就是TensorFlow，直观来看，就是张量的流动。张量(tensor)，即任意维度的数据，一维、二维、三维、四维等数据统称为张量。而张量的流动则是指保持计算节点不变，让数据进行流动。这样的设计是针对连接式的机器学习算法，比如逻辑斯底回归，神经网络等。连接式的机器学习算法可以把算法表达成一张图，张量从图中从前到后走一遍就完成了前向运算；而残差从后往前走一遍，就完成了后向传播。</p>
<h3 id="1-1-维度-Shape"><a href="#1-1-维度-Shape" class="headerlink" title="1.1 维度 (Shape)"></a>1.1 维度 (Shape)</h3><p>TensorFlow中使用了三种记号描述张量的维度：阶，形状以及维数。下表展示了他们之间的关系：</p>
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[ ]</td>
<td>0-D</td>
<td>一个0维张量是一个常量，如5</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>一个1维张量是一个矢量，如[5, 4]</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>一个2维张量是一个矩阵，如[[5, 4], [2, 3]]</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>一个3维张量是一个立方矩阵，如[[[5, 4], [2, 3]], [[5, 4], [2, 3]]</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, D2,….Dn]</td>
<td>n-D</td>
<td>一个n维张量是一个多维数组</td>
</tr>
</tbody>
</table>
<h3 id="1-2-阶（Rank）"><a href="#1-2-阶（Rank）" class="headerlink" title="1.2 阶（Rank）"></a>1.2 阶（Rank）</h3><p>在TensorFlow系统中，张量的维数来被描述为阶。但是张量的阶和矩阵的阶并不是同一个概念：张量的阶（关于如顺序、度数或者是n维）是张量维数的一个数量描述。比如，Python中的list列表就是2阶。</p>
<p>你可以认为零阶张量是一个常量；一阶张量是一个向量；二阶张量就是我们平常所说的矩阵，你可以用语句t[i, j]来访问其中的任何元素；对于三阶张量，你可以用t[i, j, k]来访问其中的任何元素。</p>
<h3 id="1-3-数据类型-Type"><a href="#1-3-数据类型-Type" class="headerlink" title="1.3 数据类型 (Type)"></a>1.3 数据类型 (Type)</h3><p>除了维度，tensor还有一个数据类型属性。你可以为一个张量指定下列数据类型中的任意一个类型：</p>
<p><img src="/2018/03/05/TensorFlow基本概念/2.png" alt=""></p>
<h2 id="2-算子-operation"><a href="#2-算子-operation" class="headerlink" title="2. 算子(operation)"></a>2. 算子(operation)</h2><p>节点被称之为op（节点也叫操作、算子，是operation的缩写）。一个op获得0个或多个tensor，执行计算产生0个或多个tensor。</p>
<h2 id="3-边（edge）"><a href="#3-边（edge）" class="headerlink" title="3. 边（edge）"></a>3. 边（edge）</h2><p>TensorFlow，字面意思就是张量的流动（flow）。<br>TF的图中的边分为两种：</p>
<ul>
<li><p>正常边，正常边上可以流动数据，即正常边就是tensor。计算图的一条边，就是一个tensor。而张量的流动则是指保持计算节点不变，让数据进行流动。tensor是一个数据类型的一维、二维、三维、四维等多维数组。例如，你可以把一组图像集表示为一个四维浮点数的数组，这四个维度分别是 [batch, height, width, channels]。</p>
</li>
<li><p>特殊边，又称作控制依赖，(control dependencies)</p>
<ul>
<li>没有数据从特殊边上流动，但是特殊边却可以控制节点之间的依赖关系，在特殊边的起始节点完成运算之前，特殊边的结束节点不会被执行。</li>
<li>也不仅仅非得有依赖关系才可以用特殊边，还可以有其他用法，比如为了控制内存的时候，可以让两个实际上并没有前后依赖关系的运算分开执行。</li>
<li>特殊边可以在client端被直接使用。</li>
</ul>
</li>
</ul>
<h2 id="4-核-kernel"><a href="#4-核-kernel" class="headerlink" title="4. 核(kernel)"></a>4. 核(kernel)</h2><p>TF中还有一个概念是kernel，kernel是operation在某种设备上的具体实现。TF的库通过注册机制来定义op和kernel，所以可以通过链接一个其他的库来进行kernel和op的扩展。</p>
<h2 id="5-计算图（graph）"><a href="#5-计算图（graph）" class="headerlink" title="5. 计算图（graph）"></a>5. 计算图（graph）</h2><p>节点和边相互连接成计算图，一个计算图描述了一次计算过程。</p>
<p>这是一个声明式的编程方式，如同做菜，我们需要先把主材和佐料都准备好，才能添油烹制。TensorFlow的计算方式也是如此。在构建阶段，我们需要把网络（如神经网络）以计算图的形式构建出来，接着启动会话（session），运行先前构建的图，得到目标结果。</p>
<h2 id="6-会话（session）"><a href="#6-会话（session）" class="headerlink" title="6. 会话（session）"></a>6. 会话（session）</h2><p>使用TensorFlow编写的程序，通常被组织成一个构建阶段和一个运行阶段：在构建阶段，操作的执行步骤被描述成一个计算图；在运行阶段，使用会话执行计算图中的操作。</p>
<p>为了得到结果，计算图必须在会话里被启动。会话将计算图的op分发到诸如CPU或GPU之类的设备上，同时提供执行op的方法。这些方法执行后，将产生的tensor返回。在Python语言中, 返回的tensor是numpy ndarray对象；在C和C++语言中，返回的tensor是tensorflow Tensor实例。</p>
<h2 id="7-变量（variable）"><a href="#7-变量（variable）" class="headerlink" title="7. 变量（variable）"></a>7. 变量（variable）</h2><p>在运行计算图过程中，变量用于维护某个参数的状态。TensorFlow通常会将一个统计模型中的参数表示为一组变量，例如你可以将一个神经网络的权重作为某个变量存储在一个tensor中。在训练过程中, 通过重复运行计算图，更新这个tensor。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="http://blog.csdn.net/weixin_30014549/article/details/52529036" target="_blank" rel="external">tensorflow原理</a></p>
<p>[2] <a href="http://blog.csdn.net/stdcoutzyx/article/details/51645396" target="_blank" rel="external">tensorflow架构</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/05/TensorFlow基本概念/" data-id="cjfg68vlr000v04wg2k470f3f" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-卷积神经网络——卷积神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/04/卷积神经网络——卷积神经网络/" class="article-date">
  <time datetime="2018-03-04T04:40:35.000Z" itemprop="datePublished">2018-03-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/04/卷积神经网络——卷积神经网络/">卷积神经网络——卷积神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>以下为在吴恩达老师的 deeplearning.ai 课程项目中，第四部分《卷积神经网络》第一周课程 “卷积神经网络基础” 关键点的笔记。本次笔记几乎涵盖了所有视频课程的内容。通过该笔记，一方面为自己学习进行记录，以便以后进行快速review，另一方面，也便于与大家进行探讨学习，错误及不足之处，还望指教。<br><!--nore--></p>
<h2 id="1-计算机视觉"><a href="#1-计算机视觉" class="headerlink" title="1. 计算机视觉"></a>1. 计算机视觉</h2><p>计算机视觉（Computer Vision）包含很多不同类别的问题，如图片分类、目标检测、图片风格迁移等等。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/1.jpg" alt=""></p>
<p>对于小尺寸的图片问题，也许我们用深度神经网络的结构可以较为简单的解决一定的问题。但是当应用在大尺寸的图片上，输入规模将变得十分庞大，使用神经网络将会有非常多的参数需要去学习，这个时候神经网络就不再适用。</p>
<p>卷积神经网络在计算机视觉问题上是一个非常好的网络结构。</p>
<h2 id="2-边缘检测示例"><a href="#2-边缘检测示例" class="headerlink" title="2. 边缘检测示例"></a>2. 边缘检测示例</h2><p>卷积运算是卷积神经网络的基本组成部分。下面以边缘检测的例子来介绍卷积运算。</p>
<p>所谓边缘检测，在下面的图中，分别通过垂直边缘检测和水平边缘检测得到不同的结果：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/2.jpg" alt=""></p>
<h3 id="垂直边缘检测："><a href="#垂直边缘检测：" class="headerlink" title="垂直边缘检测："></a>垂直边缘检测：</h3><p>假设对于一个 $6\times6$ 大小的图片（以数字表示），以及一个 $3\times3$ 大小的 filter（卷积核） 进行卷积运算，以“ * ” 符号表示。图片和垂直边缘检测器分别如左和中矩阵所示：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/3.jpg" alt=""></p>
<p>filter 不断地和其大小相同的部分做对应元素的乘法运算并求和，最终得到的数字相当于新图片的一个像素值，如右矩阵所示，最终得到一个 $4\times4$ 大小的图片。</p>
<h3 id="边缘检测的原理："><a href="#边缘检测的原理：" class="headerlink" title="边缘检测的原理："></a>边缘检测的原理：</h3><p>以一个有一条垂直边缘线的简单图片来说明。通过垂直边缘 <strong>filter</strong> 我们得到的最终结果图片可以明显地将边缘和非边缘区分出来：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/4.jpg" alt=""></p>
<p>卷积运算提供了一个方便的方法来检测图像中的边缘，成为卷积神经网络中重要的一部分。</p>
<h3 id="多种边缘检测："><a href="#多种边缘检测：" class="headerlink" title="多种边缘检测："></a>多种边缘检测：</h3><ul>
<li>垂直和水平边缘检测</li>
</ul>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/5.jpg" alt=""></p>
<ul>
<li>更复杂的 <strong>filter</strong></li>
</ul>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/6.jpg" alt=""></p>
<p>对于复杂的图片，我们可以直接将 <strong>filter</strong> 中的数字直接看作是需要学习的参数，其可以学习到对于图片检测相比上面<strong>filter</strong>更好的更复杂的 <strong>filter</strong> ，如相对于水平和垂直检测器，我们训练的 filter 参数也许可以知道不同角度的边缘。</p>
<p>通过卷积运算，在卷积神经网络中通过反向传播算法，可以学习到相应于目标结果的 <strong>filter</strong>，将其应用于整个图片，输出其提取到的所有有用的特征。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/7.jpg" alt=""></p>
<h3 id="卷积和互相关："><a href="#卷积和互相关：" class="headerlink" title="卷积和互相关："></a>卷积和互相关：</h3><p>在数学定义上，矩阵的卷积（convolution）操作为首先将卷积核同时在水平和垂直方向上进行翻转，构成一个卷积核的镜像，然后使用该镜像再和前面的矩阵进行移动相乘求和操作。如下面例子所示：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/8.jpg" alt=""></p>
<p>在深度学习中，我们称为的卷积运算实则没有卷积核变换为镜像的这一步操作，因为在权重学习的角度，变换是没有必要的。深度学习的卷积操作在数学上准确度来说称为<strong>互相关</strong>（cross-correlation）。</p>
<h2 id="3-Padding"><a href="#3-Padding" class="headerlink" title="3. Padding"></a>3. Padding</h2><h3 id="没有Padding的缺点："><a href="#没有Padding的缺点：" class="headerlink" title="没有Padding的缺点："></a>没有Padding的缺点：</h3><ul>
<li>每次卷积操作，图片会缩小；</li>
</ul>
<p>就前面的例子来说， $6\times6$ 大小的图片，经过 $3\times3$ 大小的 filter，缩小成了 $4\times4$ 大小</p>
<p>图片： $n\times n–&gt; (n-f+1)\times (n-f+1)$</p>
<ul>
<li>角落和边缘位置的像素进行卷积运算的次数少，可能会丢失有用信息。</li>
</ul>
<p>其中，$\bold n$ 表示图片的长或宽的大小，$\bold{f}$ 表示filter的长或宽的大小。</p>
<h3 id="加Padding："><a href="#加Padding：" class="headerlink" title="加Padding："></a>加Padding：</h3><p>为了解决上面的两个缺点，我们在进行卷积运算前为图片加padding，包围角落和边缘的像素，使得通过filter的卷积运算后，图片大小不变，也不会丢失角落和边沿的信息。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/9.jpg" alt=""></p>
<p>以 p 表示 Padding 的值，则输入 $n\times n$ 大小的图片，最终得到的图片大小为  $(n+2p-f+1)\times (n+2p-f+1)$ ，为使图片大小保持不变，需根据filter的大小调整p的值。</p>
<h3 id="Valid-Same-卷积："><a href="#Valid-Same-卷积：" class="headerlink" title="Valid / Same 卷积："></a>Valid / Same 卷积：</h3><ul>
<li>Valid：no padding；（ $n\times n –&gt; (n-f+1)\times (n-f+1)$ ）</li>
<li>Same：padding，<strong>输出</strong>与<strong>输入</strong>图片大小<strong>相同</strong>，（ $p=(f-1)/2$ ）。在计算机视觉中，一般来说padding的值为奇数（因为filter一般为奇数）</li>
</ul>
<h2 id="4-卷积步长（stride）"><a href="#4-卷积步长（stride）" class="headerlink" title="4. 卷积步长（stride）"></a>4. 卷积步长（stride）</h2><p>卷积的步长是构建卷积神经网络的一个基本的操作。</p>
<p>如前面的例子中，我们使用的 stride=1，每次的卷积运算以1个步长进行移动。下面是 stride=2 时对图片进行卷积的结果：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/10.jpg" alt=""></p>
<p>以 s 表示 stride 的大小，那么在进行卷积运算后，图片的变化为：</p>
<p>$n\times n –&gt; \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor\times \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor$</p>
<p>注意，在当 $padding\ne 1$ 时，若移动的窗口落在图片外面，则不要再进行相乘的操作，丢弃边缘的数值信息，所以输出图片的最终维度为<strong>向下取整</strong>。</p>
<h2 id="5-立体卷积"><a href="#5-立体卷积" class="headerlink" title="5. 立体卷积"></a>5. 立体卷积</h2><h3 id="卷积核的通道数："><a href="#卷积核的通道数：" class="headerlink" title="卷积核的通道数："></a>卷积核的通道数：</h3><p>对于灰色图像中，卷积核和图像均是二维的。而应用于彩色图像中，因为图片有R、G、B三个颜色通道，所以此时的卷积核应为三维卷积核。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/11.jpg" alt=""></p>
<p>卷积核的第三个维度需要与进行卷积运算的图片的通道数相同。</p>
<h3 id="多卷积核："><a href="#多卷积核：" class="headerlink" title="多卷积核："></a>多卷积核：</h3><p>单个卷积核应用于图片时，提取图片特定的特征，不同的卷积核提取不同的特征。如两个大小均为  $3\times3\times3$ 的卷积核分别提取图片的垂直边缘和水平边缘。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/12.jpg" alt=""></p>
<p>由图可知，最终提取到彩色图片的垂直特征图和水平特征图，得到有2个通道的 4\times4 大小的特征图片。</p>
<h3 id="Summary："><a href="#Summary：" class="headerlink" title="Summary："></a>Summary：</h3><p>图片： $(n\times n\times n<em>{c} )* (f\times f\times n</em>{c})$ ——&gt;$(n-f+1)\times (n-f+1)\times n’_{c}$</p>
<p>其中， $n<em>{c}$ 表示通道的数量， $n’</em>{c}$ 表示下一层的通道数，同时也等于本层卷积核的个数。</p>
<h2 id="6-简单卷积网络"><a href="#6-简单卷积网络" class="headerlink" title="6. 简单卷积网络"></a>6. 简单卷积网络</h2><h3 id="单层卷积网络的例子："><a href="#单层卷积网络的例子：" class="headerlink" title="单层卷积网络的例子："></a>单层卷积网络的例子：</h3><p>和普通的神经网络单层前向传播的过程类似，卷积神经网络也是一个先由输入和权重及偏置做线性运算，然后得到的结果输入一个激活函数中，得到最终的输出：</p>
<p>$$z^{[1]}=w^{[1]}a^{[0]}+b^{[1]}$$</p>
<p>$$a^{[1]}=g(z^{[1]})$$</p>
<p>不同点是：在卷积神经网络中，权重和输入进行的是卷积运算。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/13.jpg" alt=""></p>
<h3 id="单层卷积的参数个数："><a href="#单层卷积的参数个数：" class="headerlink" title="单层卷积的参数个数："></a>单层卷积的参数个数：</h3><p>在一个卷积层中，如果我们有10个 $3\times3\times3$ 大小的卷积核，那么加上每个卷积核对应的偏置，则对于一个卷积层，我们共有的参数个数为：</p>
<p>$$(3\times3\times3+1)\times10 = 280$$</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/14.jpg" alt=""></p>
<p>无论图片大小是多少，该例子中的卷积层参数个数一直都是280个，相对于普通的神经网络，卷积神经网络的参数个数要少很多。</p>
<h3 id="标记的总结："><a href="#标记的总结：" class="headerlink" title="标记的总结："></a>标记的总结：</h3><p>如果 $l$ 表示一个卷积层：</p>
<ol>
<li>$f^{[l]}$ ：filter 的大小；</li>
<li>$p^{[l]}$ ：padding；</li>
<li>$s^{[l]}$ ：步长（stride）；</li>
<li>卷积核的个数： $n^{[l]}_{C}$ ；</li>
<li>filter大小： $f^{[l]}\times f^{[l]}\times n^{[l-1]}_{C}$ ;</li>
<li>激活值（Activations）： $a^{[l]}$—&gt;$n^{[l]}<em>{H}\times n^{[l]}</em>{W}\times n^{[l]}_{C}$；</li>
<li>权重（Weights）： $f^{[l]}\times f^{[l]}\times n^{[l-1]}<em>{C}\times n^{[l]}</em>{C}$ ；</li>
<li>偏置（bias）： $n^{[l]}<em>{C}$ — — $(1,1,1,n^{[l]}</em>{C})$</li>
</ol>
<ul>
<li>Input： $n^{[l-1]}<em>{H}\times n^{[l-1]}</em>{W}\times n^{[l-1]}_{C}$ ；</li>
<li>Output： $n^{[l]}<em>{H}\times n^{[l]}</em>{W}\times n^{[l]}_{C}$ ；</li>
</ul>
<p>其中， $n^{[l]}<em>{H} = \left\lfloor \dfrac{n^{[l-1]}</em>{H}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \right\rfloor$ ， $n^{[l]}<em>{W} = \left\lfloor \dfrac{n^{[l-1]}</em>{W}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \right\rfloor$ 。</p>
<h3 id="简单卷积网络示例："><a href="#简单卷积网络示例：" class="headerlink" title="简单卷积网络示例："></a>简单卷积网络示例：</h3><p>多层卷积构成卷积神经网络，下面是一个卷积神经网络的例子：</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/15.jpg" alt=""></p>
<p>卷积网络层的类型：</p>
<ul>
<li>卷积层（Convolution），Conv；</li>
<li>池化层（Pooling），Pool；</li>
<li>全连接层（Fully connected）：Fc；</li>
</ul>
<h2 id="7-池化层"><a href="#7-池化层" class="headerlink" title="7. 池化层"></a>7. 池化层</h2><h3 id="最大池化（Max-pooling）："><a href="#最大池化（Max-pooling）：" class="headerlink" title="最大池化（Max pooling）："></a>最大池化（Max pooling）：</h3><p>最大池化是对前一层得到的特征图进行池化减小，仅由当前小区域内的最大值来代表最终池化后的值。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/16.jpg" alt=""></p>
<p>在最大池化中，有一组超参数需要进行调整，其中， f 表示池化的大小， s 表示步长。</p>
<ul>
<li>池化前： $n \times n$ ；</li>
<li>池化后： $\left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor\times \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor$ 。</li>
</ul>
<h3 id="平均池化（Average-pooling）："><a href="#平均池化（Average-pooling）：" class="headerlink" title="平均池化（Average pooling）："></a>平均池化（Average pooling）：</h3><p>平均池化与最大池化唯一不同的是其选取的是小区域内的均值来代表该区域内的值。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/17.jpg" alt=""></p>
<h3 id="Pooling-Summary："><a href="#Pooling-Summary：" class="headerlink" title="Pooling Summary："></a>Pooling Summary：</h3><p>池化层的超参数：</p>
<ul>
<li>f ：filter的大小；</li>
<li>s ：stride大小；</li>
<li>最大池化或者平均池化；</li>
<li>p ：padding，这里要注意，几乎很少使用。</li>
</ul>
<p>注意，池化层没有需要学习的参数。</p>
<h2 id="8-卷积神经网络示例"><a href="#8-卷积神经网络示例" class="headerlink" title="8. 卷积神经网络示例"></a>8. 卷积神经网络示例</h2><p>这里以 <strong>LeNet-5</strong> 为例，给出一个完整的卷积神经网络。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/18.jpg" alt=""></p>
<p>构建深度卷积的模式：</p>
<ul>
<li>随着网络的深入，提取的特征图片大小将会逐渐减小，但同时通道数量应随之增加；</li>
<li>Conv——Pool——Conv——Pool——Fc——Fc——Fc——softmax。</li>
</ul>
<h3 id="卷积神经网络的参数："><a href="#卷积神经网络的参数：" class="headerlink" title="卷积神经网络的参数："></a>卷积神经网络的参数：</h3><p><img src="/2018/03/04/卷积神经网络——卷积神经网络/19.jpg" alt=""></p>
<p>根据上表我们可以看出，对于卷积卷积神经网络的参数：</p>
<ul>
<li>在卷积层，仅有少量的参数；</li>
<li>在池化层，没有参数；</li>
<li>在全连接层，存在大量的参数。</li>
</ul>
<h2 id="9-使用卷积神经网络"><a href="#9-使用卷积神经网络" class="headerlink" title="9. 使用卷积神经网络"></a>9. 使用卷积神经网络</h2><h3 id="参数少的优势："><a href="#参数少的优势：" class="headerlink" title="参数少的优势："></a>参数少的优势：</h3><p>与普通的全连接神经网络相比，卷积神经网络的参数更少。如图中的例子，卷积神经网络仅有  6\times(5\times5+1)=156 个参数，而普通的全连接网络有 3072\times4704\approx 14M 个参数。</p>
<p><img src="/2018/03/04/卷积神经网络——卷积神经网络/20.jpg" alt=""></p>
<ul>
<li>参数共享：一个特征检测器（filter）对图片的一部分有用的同时也有可能对图片的另外一部分有用。</li>
<li>连接的稀疏性：在每一层中，每个输出值只取决于少量的输入。</li>
</ul>
<h3 id="训练卷积神经网络："><a href="#训练卷积神经网络：" class="headerlink" title="训练卷积神经网络："></a>训练卷积神经网络：</h3><p><img src="/2018/03/04/卷积神经网络——卷积神经网络/21.jpg" alt=""></p>
<p>我们将训练集输入到卷积神经网络中，对网络进行训练。利用梯度下降（Adam、momentum等优化算法）最小化代价函数来寻找网络的最优参数。</p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p>[1] deeplearning.ai 课件</p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/30800318" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/30800318</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/03/04/卷积神经网络——卷积神经网络/" data-id="cjfg68vml002704wgmpuhxb1n" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TensorFlow——Math" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/26/TensorFlow——Math/" class="article-date">
  <time datetime="2018-02-26T07:03:42.000Z" itemprop="datePublished">2018-02-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/26/TensorFlow——Math/">TensorFlow API——Math</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要对tf的一些数学操作方法进行汇总。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/02/26/TensorFlow——Math/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/02/26/TensorFlow——Math/" data-id="cjfg68vll000o04wg0z5fzrtv" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Python-yield-及其实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/06/Python-yield-及其实现/" class="article-date">
  <time datetime="2018-02-06T12:15:15.000Z" itemprop="datePublished">2018-02-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python/">Python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/06/Python-yield-及其实现/">Python yield 及其实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Python-yield及其实现"><a href="#Python-yield及其实现" class="headerlink" title="Python yield及其实现"></a>Python yield及其实现</h1><p>刚开始接触python时，解接触到了 yield 关键字，在实际使用中，越来越觉得其用处的强大，遂感觉需整理一下自己的理解，做一个总结。yield 的功能类似于 return，但不同之处在于它返回的是生成器。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/02/06/Python-yield-及其实现/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/02/06/Python-yield-及其实现/" data-id="cjfg68vlh000k04wg7rzv6x7g" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/yield-产生器-生成器/">yield 产生器 生成器</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TensorFlow-api-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/31/TensorFlow-api-1/" class="article-date">
  <time datetime="2018-01-31T15:24:08.000Z" itemprop="datePublished">2018-01-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/31/TensorFlow-api-1/">TensorFlow-api(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="TensorFlow-api-1-：tf-reduce-mean-这类函数"><a href="#TensorFlow-api-1-：tf-reduce-mean-这类函数" class="headerlink" title="TensorFlow-api(1)：tf.reduce_mean()这类函数"></a>TensorFlow-api(1)：tf.reduce_mean()这类函数</h1><p>在tensor的某一维度上，有一类求值的函数，如tf.reduce_max( )，tf.reduce_mean( )，tf.reduce_sum( )<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/31/TensorFlow-api-1/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/31/TensorFlow-api-1/" data-id="cjfg68vlu000y04wguh216nhi" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/">Next&raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/yespon" target="_blank" title="Github"></a>
      
      
            <a class="weibo" aria-hidden="true"  href="http://weibo.com/yespon" target="_blank" title="微博"></a>
      
      
              <a class="zhihu" aria-hidden="true"  href="http://www.zhihu.com/people/yespon" target="_blank" title="知乎"></a>
      
      
            <a class="email" aria-hidden="true"  href="mailto:yespon@qq.com" target="_blank" title="邮箱"></a>
      
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title categories">Categories</h3>
    <div class="widget" id="categories">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Framework-Tools/">Framework&Tools</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器技术/">服务器技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">30</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/">架构&设计</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/经典文摘/">经典文摘</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNN-AlexNet/" style="font-size: 14px; color: #00f">CNN AlexNet</a> <a href="/tags/CUDA-GPUs/" style="font-size: 14px; color: #00f">CUDA GPUs</a> <a href="/tags/LDAP/" style="font-size: 14px; color: #00f">LDAP</a> <a href="/tags/MQ/" style="font-size: 19.5px; color: #7741f7">MQ</a> <a href="/tags/NLP/" style="font-size: 14px; color: #00f">NLP</a> <a href="/tags/Nginx/" style="font-size: 14px; color: #00f">Nginx</a> <a href="/tags/Sticky/" style="font-size: 14px; color: #00f">Sticky</a> <a href="/tags/TF-IDF/" style="font-size: 14px; color: #00f">TF-IDF</a> <a href="/tags/TensorFlow/" style="font-size: 16.75px; color: #3c21fb">TensorFlow</a> <a href="/tags/Tensorflow/" style="font-size: 22.25px; color: #b362f2">Tensorflow</a> <a href="/tags/UUID/" style="font-size: 14px; color: #00f">UUID</a> <a href="/tags/decorator/" style="font-size: 14px; color: #00f">decorator</a> <a href="/tags/deeplearning-ai/" style="font-size: 25px; color: #ee82ee">deeplearning.ai</a> <a href="/tags/kNN-算法/" style="font-size: 16.75px; color: #3c21fb">kNN 算法</a> <a href="/tags/pandas-read-csv/" style="font-size: 14px; color: #00f">pandas read_csv</a> <a href="/tags/quarts/" style="font-size: 14px; color: #00f">quarts</a> <a href="/tags/schedule/" style="font-size: 14px; color: #00f">schedule</a> <a href="/tags/sklearn/" style="font-size: 14px; color: #00f">sklearn</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #00f">tensorflow</a> <a href="/tags/yield-产生器-生成器/" style="font-size: 14px; color: #00f">yield 产生器 生成器</a> <a href="/tags/似然估计-likehood/" style="font-size: 14px; color: #00f">似然估计 likehood</a> <a href="/tags/余弦相似度/" style="font-size: 14px; color: #00f">余弦相似度</a> <a href="/tags/分布式/" style="font-size: 14px; color: #00f">分布式</a> <a href="/tags/反向代理/" style="font-size: 14px; color: #00f">反向代理</a> <a href="/tags/唯一性ID/" style="font-size: 14px; color: #00f">唯一性ID</a> <a href="/tags/性能指标/" style="font-size: 14px; color: #00f">性能指标</a> <a href="/tags/机器学习总结/" style="font-size: 16.75px; color: #3c21fb">机器学习总结</a> <a href="/tags/模型评估/" style="font-size: 14px; color: #00f">模型评估</a> <a href="/tags/消息中间件/" style="font-size: 19.5px; color: #7741f7">消息中间件</a> <a href="/tags/神经网络-NN/" style="font-size: 14px; color: #00f">神经网络 NN</a> <a href="/tags/装饰器/" style="font-size: 14px; color: #00f">装饰器</a> <a href="/tags/集群/" style="font-size: 14px; color: #00f">集群</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/29/面试总结/">面试总结</a>
          </li>
        
          <li>
            <a href="/2018/03/22/卷积神经网络——目标检测/">卷积神经网络——目标检测</a>
          </li>
        
          <li>
            <a href="/2018/03/16/TF-IDF与余弦相似性/">TF-IDF与余弦相似性</a>
          </li>
        
          <li>
            <a href="/2018/03/14/ML—模型评估方法/">ML—模型评估方法</a>
          </li>
        
          <li>
            <a href="/2018/03/13/sklearn-preprocessing-数据预处理（OneHotEncoder）/">sklearn preprocessing 数据预处理（OneHotEncoder）</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="http://yespon.github.io">yespon&#39;s blog</a>
            </li>
            
        </ul>
    </div>
</div>

  
    <!--微信公众号二维码-->

  <div class="widget-wrap">
    <h3 class="follow-title ">WeChat</h3>
    <div class="widget wechat-widget">
        <img src="/images/wechat_yespon.jpg" alt="扫码关注" width="250"/>
    </div>
  </div>


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 Yespon&nbsp;|&nbsp;
      Theme by <a href="https://github.com/yespon/hexo-theme-yespon/" target="_blank">Yespon</a>
    </div>
     <div id="footer-right">
      Contact&nbsp;|&nbsp;yespon#qq.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/categories" class="mobile-nav-link">Category</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script> 
  <script>
  var gitment = new Gitment({
    // id: '页面 ID', // 可选。默认为 location.href
    owner: 'yespon',
    repo: 'yespon.github.io',
    oauth: {
    client_id: '4ab181ded22ebacbab72',
    client_secret: 'c3cd3df382f34a5685a1608234223423248250f7',
    }
  })
  gitment.render(document.getElementById("gitment_comments"))
</script>


<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>