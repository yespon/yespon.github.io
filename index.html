<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Life Designer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Life Designer, design by oneself!">
<meta property="og:type" content="website">
<meta property="og:title" content="Life Designer">
<meta property="og:url" content="http://yespon.github.io/index.html">
<meta property="og:site_name" content="Life Designer">
<meta property="og:description" content="Life Designer, design by oneself!">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Designer">
<meta name="twitter:description" content="Life Designer, design by oneself!">
  
    <link rel="alternate" href="/atom.xml" title="Life Designer" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yespon.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/categories">Category</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Designer</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Life Designer, design by oneself!</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-改善深层神经网络——超参数调试、Batch正则化和程序框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" class="article-date">
  <time datetime="2018-01-14T02:39:49.000Z" itemprop="datePublished">2018-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/">改善深层神经网络——超参数调试、Batch正则化和程序框架</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="超参数调试、Batch正则化和程序框架"><a href="#超参数调试、Batch正则化和程序框架" class="headerlink" title="超参数调试、Batch正则化和程序框架"></a>超参数调试、Batch正则化和程序框架</h1><h2 id="超参数的调试处理"><a href="#超参数的调试处理" class="headerlink" title="超参数的调试处理"></a>超参数的调试处理</h2><p>在机器学习领域，超参数比较少的情况下，我们之前利用设置网格点的方式来调试超参数；<br>但在深度学习领域，超参数较多的情况下，不是设置规则的网格点，而是随机选择点进行调试。这样做是因为在我们处理问题的时候，是无法知道哪个超参数是更重要的，所以随机的方式去测试超参数点的性能，更为合理，这样可以探究更超参数的潜在价值。</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/1.jpg" alt=""></p>
<h2 id="为超参数选择合适的范围"><a href="#为超参数选择合适的范围" class="headerlink" title="为超参数选择合适的范围"></a>为超参数选择合适的范围</h2><h3 id="Scale均匀随机"><a href="#Scale均匀随机" class="headerlink" title="Scale均匀随机"></a>Scale均匀随机</h3><p>在超参数选择的时候，一些超参数是在一个范围内进行均匀随机取值，如隐藏层神经元结点的个数、隐藏层的层数等。但是有一些超参数的选择做均匀随机取值是不合适的，这里需要按照一定的比例在不同的小范围内进行均匀随机取值，以学习率 $\alpha$ 的选择为例，在 $0.001,\ldots,1$ 范围内进行选择：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/2.jpg" alt=""></p>
<p>如上图所示，如果在 $0.001,\ldots,1$ 的范围内进行进行均匀随机取值，则有90% 的概率 选择范围在 $0.1\sim1$ 之间，而只有 10% 的概率才能选择到$0.001\sim0.1$ 之间，显然是不合理的。</p>
<p>所以在选择的时候，在不同比例范围内进行均匀随机取值，如 $0.001\sim0.001$ 、 $0.001\sim0.01$ 、 $0.01\sim0.1$ 、 $0.1\sim1$ 范围内选择。</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">r = <span class="number">-4</span> * np.random.rand()     <span class="comment"># r in [-4,0]</span></div><div class="line">learning_rate = <span class="number">10</span> ** r      <span class="comment"># 10^&#123;r&#125;</span></div></pre></td></tr></table></figure>
<p>一般地，如果在 $10^{a}\sim10^{b}$ 之间的范围内进行按比例的选择，则 $r \in [a, b]$ ， $\alpha = 10^{r}$ 。</p>
<p>同样，在使用指数加权平均的时候，超参数 \beta 也需要用上面这种方向进行选择。</p>
<h2 id="超参数调试实践-Pandas-vs-Caviar"><a href="#超参数调试实践-Pandas-vs-Caviar" class="headerlink" title="超参数调试实践: Pandas vs. Caviar"></a>超参数调试实践: Pandas vs. Caviar</h2><p>在超参数调试的实际操作中，我们需要根据我们现有的计算资源来决定以什么样的方式去调试超参数，进而对模型进行改进。下面是不同情况下的两种方式：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/3.jpg" alt=""></p>
<ol>
<li>在计算资源有限的情况下，使用第一种，仅调试一个模型，每天不断优化；</li>
<li>在计算资源充足的情况下，使用第二种，同时并行调试多个模型，选取其中最好的模型。</li>
</ol>
<h2 id="网络中激活值的归一化"><a href="#网络中激活值的归一化" class="headerlink" title="网络中激活值的归一化"></a>网络中激活值的归一化</h2><p>在 Logistic Regression 中，将输入特征进行归一化，可以加速模型的训练。那么对于更深层次的神经网络，我们是否可以归一化隐藏层的输出 $a^{[l]}$ 或者经过激活函数前的 z^{[l]} ，以便加速神经网络的训练过程？答案是肯定的。</p>
<p>常用的方式是将隐藏层的经过激活函数前的 $z^{[l]}$ 进行归一化。</p>
<h3 id="Batch-Norm-的实现"><a href="#Batch-Norm-的实现" class="headerlink" title="Batch Norm 的实现"></a>Batch Norm 的实现</h3><p>以神经网络中某一隐藏层的中间值为例： $z^{(1)},z^{(2)},\ldots,z^{(m)}$ ：</p>
<p>$$\mu = \dfrac{1}{m}\sum\limits_{i}z^{(i)}$$</p>
<p>$$\sigma^{2}=\dfrac{1}{m}\sum\limits_{i}(z^{(i)}-\mu)^{2}$$</p>
<p>$$z^{(i)}_{\rm norm} = \dfrac{z^{(i)}-\mu}{\sqrt{\sigma^{2}+\varepsilon}}$$</p>
<p>这里加上 $\varepsilon$ 是为了保证数值的稳定。</p>
<p>到这里所有 $z$ 的分量都是平均值为 0 和方差为 1 的分布，但是我们不希望隐藏层的单元总是如此，也许不同的分布会更有意义，所以我们再进行计算：</p>
<p>$$\widetilde z^{(i)} = \gamma z^{(i)}_{\rm norm}+\beta$$</p>
<p>这里 $\gamma$ 和 $\beta$ 是可以更新学习的参数，如神经网络的权重 $w$ 一样，两个参数的值来确定 $\widetilde z^{(i)}$ 所属的分布。</p>
<h2 id="在神经网络中融入Batch-Norm"><a href="#在神经网络中融入Batch-Norm" class="headerlink" title="在神经网络中融入Batch Norm"></a>在神经网络中融入Batch Norm</h2><p>在深度神经网络中应用Batch Norm，这里以一个简单的神经网络为例，前向传播的计算流程如下图所示：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/4.jpg" alt=""></p>
<h3 id="实现梯度下降"><a href="#实现梯度下降" class="headerlink" title="实现梯度下降"></a>实现梯度下降</h3><hr>
<ul>
<li><p>for t = 1 … num （这里num 为Mini Batch 的数量）：</p>
<ul>
<li>在每一个X^{t}上进行前向传播（forward prop）的计算：<ul>
<li>在每个隐藏层都用 Batch Norm 将 $z^{[l]}$ 替换为 $\widetilde z^{[l]}$</li>
</ul>
</li>
<li>使用反向传播（Back prop）计算各个参数的梯度： $dw^{[l]}$、$d\gamma^{[l]}$、$d\beta^{[l]}$</li>
<li><p>更新参数：</p>
<ul>
<li>$w^{[l]}:=w^{[l]}-\alpha dw^{[l]}$</li>
<li>$\gamma^{[l]}:=\gamma^{[l]}-\alpha d\gamma^{[l]}$</li>
<li>$\beta^{[l]}:=\beta^{[l]}-\alpha d\beta^{[l]}$</li>
</ul>
</li>
</ul>
</li>
<li><p>与 Mini-batch 梯度下降法一样，Batch Norm 同样适用于 momentum、RMSprop、Adam 的梯度下降法来进行参数更新。</p>
</li>
</ul>
<hr>
<h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><p>这里没有写出偏置参数 $b^{[l]}$ 是因为 $z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}$ ，而Batch Norm 要做的就是将 $z^{[l]}$ 归一化，结果成为均值为0，标准差为1的分布，再由 $\beta$ 和 $\gamma$ 进行重新的分布缩放，那就是意味着，无论 $b^{[l]}$ 值为多少，在这个过程中都会被减去，不会再起作用。所以如果在神经网络中应用 Batch Norm 的话，就直接将偏置参数 $b^{[l]}$ 去掉，或者将其置零。</p>
<h2 id="Batch-Norm-起作用的原因"><a href="#Batch-Norm-起作用的原因" class="headerlink" title="Batch Norm 起作用的原因"></a>Batch Norm 起作用的原因</h2><h3 id="First-Reason"><a href="#First-Reason" class="headerlink" title="First Reason"></a>First Reason</h3><p>首先Batch Norm 可以加速神经网络训练的原因和输入层的输入特征进行归一化，从而改变Cost function的形状，使得每一次梯度下降都可以更快的接近函数的最小值点，从而加速模型训练过程的原理是有相同的道理。</p>
<p>只是Batch Norm 不是单纯的将输入的特征进行归一化，而是将各个隐藏层的激活函数的激活值进行的归一化，并调整到另外的分布。</p>
<h3 id="Second-Reason"><a href="#Second-Reason" class="headerlink" title="Second Reason"></a>Second Reason</h3><p>Batch Norm 可以加速神经网络训练的另外一个原因是它可以使权重比网络更滞后或者更深层。</p>
<p>下面是一个判别是否是猫的分类问题，假设第一训练样本的集合中的猫均是黑猫，而第二个训练样本集合中的猫是各种颜色的猫。如果我们将第二个训练样本直接输入到用第一个训练样本集合训练出的模型进行分类判别，那么我们在很大程度上是无法保证能够得到很好的判别结果。</p>
<p>这是因为第一个训练集合中均是黑猫，而第二个训练集合中各色猫均有，虽然都是猫，但是很大程度上样本的分布情况是不同的，所以我们无法保证模型可以仅仅通过黑色猫的样本就可以完美的找到完整的决策边界。第二个样本集合相当于第一个样本的分布的改变，称为：Covariate shift。如下图所示：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/5.jpg" alt=""></p>
<p>那么存在 Covariate shift 的问题如何应用在神经网络中？就是利用 Batch Norm 来实现。如下面的网络结构：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/6.jpg" alt=""></p>
<p>网络的目的是通过不断的训练，最后输出一个更加接近于真实值的 $\hat y$ 。现在以第2个隐藏层为输入来看：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/7.jpg" alt=""></p>
<p>对于后面的神经网络，是以第二层隐层的输出值 $a^{[2]}$ 作为输入特征的，通过前向传播得到最终的 $\hat y$ ，但是因为我们的网络还有前面两层，由于训练过程，参数 $w^{[1]}$，$w^{[2]}$ 是不断变化的，那么也就是说对于后面的网络， $a^{[2]}$ 的值也是处于不断变化之中，所以就有了Covariate shift的问题。</p>
<p>那么如果对 $z^{[2]}$ 使用了 Batch Norm，那么即使其值不断的变化，但是其均值和方差却会保持。那么 Batch Norm 的作用便是其限制了前层的参数更新导致对后面网络数值分布程度的影响，使得输入后层的数值变得更加稳定。另一个角度就是可以看作，Batch Norm 削弱了前层参数与后层参数之间的联系，使得网络的每层都可以自己进行学习，相对其他层有一定的独立性，这会有助于加速整个网络的学习。</p>
<h3 id="Batch-Norm-正则化效果"><a href="#Batch-Norm-正则化效果" class="headerlink" title="Batch Norm 正则化效果"></a>Batch Norm 正则化效果</h3><p>Batch Norm 还有轻微的正则化效果。</p>
<p>这是因为在使用Mini-batch梯度下降的时候，每次计算均值和偏差都是在一个Mini-batch上进行计算，而不是在整个数据样集上。这样就在均值和偏差上带来一些比较小的噪声。那么用均值和偏差计算得到的 $\widetilde z^{[l]}$ 也将会加入一定的噪声。</p>
<p>所以和 Dropout 相似，其在每个隐藏层的激活值上加入了一些噪声，（这里因为Dropout 以一定的概率给神经元乘上0或者1）。所以和 Dropout 相似，Batch Norm 也有轻微的正则化效果。</p>
<p>这里引入一个小的细节就是，如果使用Batch Norm ，那么使用大的Mini-batch如256，相比使用小的Mini-batch（如64），会引入跟少的噪声，那么就会减少正则化的效果。</p>
<h2 id="在测试数据上使用-Batch-Norm"><a href="#在测试数据上使用-Batch-Norm" class="headerlink" title="在测试数据上使用 Batch Norm"></a>在测试数据上使用 Batch Norm</h2><p>训练过程中，我们是在每个Mini-batch使用Batch Norm，来计算所需要的均值 $\mu$  和方差 $\sigma^{2}$ 。但是在测试的时候，我们需要对每一个测试样本进行预测，无法计算均值和方差。</p>
<p>此时，我们需要单独进行估算均值 $\mu$  和方差 $\sigma^{2}$ 。通常的方法就是在我们训练的过程中，对于训练集的Mini-batch，使用指数加权平均，当训练结束的时候，得到指数加权平均后的均值  $\mu$  和方差 $\sigma^{2}$ ，而这些值直接用于Batch Norm公式的计算，用以对测试样本进行预测。</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/8.jpg" alt=""></p>
<h2 id="Softmax-回归"><a href="#Softmax-回归" class="headerlink" title="Softmax 回归"></a>Softmax 回归</h2><p>在多分类问题中，有一种 logistic regression的一般形式，叫做Softmax regression。Softmax回归可以将多分类任务的输出转换为各个类别可能的概率，从而将最大的概率值所对应的类别作为输入样本的输出类别。</p>
<h3 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h3><p>下图是Softmax的公式以及一个简单的例子：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/9.jpg" alt=""></p>
<p>可以看出Softmax通过向量 $z^{[L]}$ 计算出总和为1的四个概率。</p>
<p>在没有隐藏隐藏层的时候，直接对Softmax层输入样本的特点，则在不同数量的类别下，Sotfmax层的作用：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/10.jpg" alt=""></p>
<h2 id="训练-Sotfmax-分类器"><a href="#训练-Sotfmax-分类器" class="headerlink" title="训练 Sotfmax 分类器"></a>训练 Sotfmax 分类器</h2><h3 id="理解-Sotfmax"><a href="#理解-Sotfmax" class="headerlink" title="理解 Sotfmax"></a>理解 Sotfmax</h3><p>为什么叫做Softmax？我们以前面的例子为例，由 $z^{[L]}$ 到 $a^{[L]}$ 的计算过程如下：</p>
<p><img src="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/11.jpg" alt=""></p>
<p>通常我们判定模型的输出类别，是将输出的最大值对应的类别判定为该模型的类别，也就是说最大值为的位置1，其余位置为0，这也就是所谓的“hardmax”。而Sotfmax将模型判定的类别由原来的最大数字5，变为了一个最大的概率0.842，这相对于“hardmax”而言，输出更加“soft”而没有那么“hard”。</p>
<p>Sotfmax回归 将 logistic回归 从二分类问题推广到了多分类问题上。</p>
<h3 id="Softmax-的-Loss-function"><a href="#Softmax-的-Loss-function" class="headerlink" title="Softmax 的 Loss function"></a>Softmax 的 Loss function</h3><p>在使用Sotfmax层时，对应的目标值 y 以及训练结束前某次的输出的概率值 $\hat y$ 分别为：</p>
<p>$$y=\left[ \begin{array}{l} 0\1\0\0 \end{array} \right] , \ \hat y=\left[ \begin{array}{l} 0.3\0.2\0.1\0.4 \end{array} \right]$$</p>
<p>Sotfmax使用的 Loss function 为：</p>
<p>$$L(\hat y,y)=-\sum\limits<em>{j=1}^{4}y</em>{j}\log \hat y_{j}$$</p>
<p>在训练过程中，我们的目标是最小化Loss function，由目标值我们可以知道， $y<em>{1}=y</em>{3}=y<em>{4}=0, y</em>{2}=1$ ，所以代入 $L(\hat y,y)$ 中，有：</p>
<p>$$L(\hat y,y)=-\sum\limits<em>{j=1}^{4}y</em>{j}\log \hat y<em>{j}=-y</em>{2}\log \hat y<em>{2}=-\log \hat y</em>{2}$$</p>
<p>所以为了最小化Loss function，我们的目标就变成了使得 \hat y_{2} 的概率尽可能的大。</p>
<p>也就是说，这里的损失函数的作用就是找到你训练集中的真实的类别，然后使得该类别相应的概率尽可能地高，这其实是最大似然估计的一种形式。</p>
<p>对应的Cost function如下：</p>
<p>$$J(w^{[1]},b^{[1]},\ldots)=\dfrac{1}{m}\sum\limits_{i=1}^{m}L(\hat y^{(i)},y^{(i)})$$</p>
<h3 id="Softmax-的梯度下降"><a href="#Softmax-的梯度下降" class="headerlink" title="Softmax 的梯度下降"></a>Softmax 的梯度下降</h3><p>在Softmax层的梯度计算公式为：</p>
<p>$$\dfrac{\partial J}{\partial z^{[L]}}=dz^{[L]} = \hat y -y$$</p>
<p>[1] 吴恩达网络云课堂 deeplearning.ai 课程</p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/30146018" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/30146018</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" data-id="cjce7u9fv001z5cwgqkqwnrxs" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——优化算法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/13/改善深层神经网络——优化算法/" class="article-date">
  <time datetime="2018-01-13T12:41:17.000Z" itemprop="datePublished">2018-01-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/13/改善深层神经网络——优化算法/">改善深层神经网络——优化算法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="Mini-batch-梯度下降法"><a href="#Mini-batch-梯度下降法" class="headerlink" title="Mini-batch 梯度下降法"></a>Mini-batch 梯度下降法</h2><p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/13/改善深层神经网络——优化算法/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/13/改善深层神经网络——优化算法/" data-id="cjce7u9fe001r5cwg1ag93ydt" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——深度学习的实践方面" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/12/改善深层神经网络——深度学习的实践方面/" class="article-date">
  <time datetime="2018-01-12T12:09:15.000Z" itemprop="datePublished">2018-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/12/改善深层神经网络——深度学习的实践方面/">改善深层神经网络——深度学习的实用层面</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="深度学习的实用层面"><a href="#深度学习的实用层面" class="headerlink" title="深度学习的实用层面"></a>深度学习的实用层面</h1><h2 id="训练-验证-测试集"><a href="#训练-验证-测试集" class="headerlink" title="训练/验证/测试集"></a>训练/验证/测试集</h2><p>对于一个需要解决的问题的样本数据，在建立模型的过程中，我们会将问题的data划分为以下几个部分：</p>
<ol>
<li><strong>训练集（train set）</strong>：用训练集对算法或模型进行训练过程；</li>
<li><strong>验证集（development set）</strong>：利用验证集或者又称为简单交叉验证集（hold-out cross validation set）进行交叉验证，选择出最好的模型；</li>
<li><strong>测试集（test set）</strong>：最后利用测试集对模型进行测试，获取模型运行的无偏估计。</li>
</ol>
        
          <p class="article-more-link">
            <a href="/2018/01/12/改善深层神经网络——深度学习的实践方面/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/12/改善深层神经网络——深度学习的实践方面/" data-id="cjce7u9fr001u5cwgcbnig2vp" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-神经网络和深度学习——深层神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/12/神经网络和深度学习——深层神经网络/" class="article-date">
  <time datetime="2018-01-12T01:29:05.000Z" itemprop="datePublished">2018-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/12/神经网络和深度学习——深层神经网络/">神经网络和深度学习——深层神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="深层神经网络"><a href="#深层神经网络" class="headerlink" title="深层神经网络"></a>深层神经网络</h1><h2 id="矩阵的维度"><a href="#矩阵的维度" class="headerlink" title="矩阵的维度"></a>矩阵的维度</h2><p>DNN结构示意图如图所示：</p>
<p><img src="/2018/01/12/神经网络和深度学习——深层神经网络/1.jpg" alt=""><br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/12/神经网络和深度学习——深层神经网络/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/12/神经网络和深度学习——深层神经网络/" data-id="cjce7u9gm00315cwgrw7f3i5u" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-DeepLearning-ai学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/11/DeepLearning-ai学习笔记/" class="article-date">
  <time datetime="2018-01-11T13:19:48.000Z" itemprop="datePublished">2018-01-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/11/DeepLearning-ai学习笔记/">DeepLearning.ai学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>学习的东西一段时间不使用总归是需要回顾一下的，学而时习之嘛！更何况毕竟不再年轻-_-！在学习DeepLearning.ai的过程中，将自己认为较为核心的东西记录下来，以便之后进行复习。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/11/DeepLearning-ai学习笔记/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/11/DeepLearning-ai学习笔记/" data-id="cjce7u9da00015cwgzlzvdnk7" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-神经网络和深度学习-——-浅层神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/11/神经网络和深度学习-——-浅层神经网络/" class="article-date">
  <time datetime="2018-01-11T13:15:43.000Z" itemprop="datePublished">2018-01-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/11/神经网络和深度学习-——-浅层神经网络/">神经网络和深度学习 —— 浅层神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="浅层神经网络"><a href="#浅层神经网络" class="headerlink" title="浅层神经网络"></a>浅层神经网络</h1><h2 id="神经网络表示"><a href="#神经网络表示" class="headerlink" title="神经网络表示"></a>神经网络表示</h2><p>一个浅层神经网络示意图：</p>
<p><img src="/2018/01/11/神经网络和深度学习-——-浅层神经网络/1.jpg" alt=""></p>
<p>如图所示，表示一个单隐层的网络结构。</p>
<p>这里主要需要注意的是，层与层之间参数矩阵的规格大小：<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/11/神经网络和深度学习-——-浅层神经网络/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/11/神经网络和深度学习-——-浅层神经网络/" data-id="cjce7u9gm002z5cwgk5yj5c2t" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-机器学习固本强基系列之正则化" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/09/机器学习固本强基系列之正则化/" class="article-date">
  <time datetime="2018-01-09T06:29:34.000Z" itemprop="datePublished">2018-01-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/09/机器学习固本强基系列之正则化/">机器学习固本强基系列之正则化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/09/机器学习固本强基系列之正则化/" data-id="cjce7u9g6002e5cwgh3lntdlz" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  
    <article id="post-kNNHandWritingClassifier" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/28/kNNHandWritingClassifier/" class="article-date">
  <time datetime="2017-12-28T03:56:02.000Z" itemprop="datePublished">2017-12-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/28/kNNHandWritingClassifier/">使用kNN算法的手写识别系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="使用kNN算法的手写识别系统"><a href="#使用kNN算法的手写识别系统" class="headerlink" title="使用kNN算法的手写识别系统"></a>使用kNN算法的手写识别系统</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">1. 收集数据：提供文本文件</div><div class="line">2. 准备数据：编写函数classify0（），将图像格式转换为分类器使用的list格式</div><div class="line">3. 分析数据：在Python命令提示符中检察数据，确保它符合要求</div><div class="line">4. 训练数据：此步骤不适用kNN</div><div class="line">5. 测试算法：编写函数使用提供的部分数据集作为测试样本，另一部分作为验证样本</div><div class="line">6. 使用算法：</div></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/2017/12/28/kNNHandWritingClassifier/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2017/12/28/kNNHandWritingClassifier/" data-id="cjce7u9ev00135cwgjyw8nkaa" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kNN-算法/">kNN 算法</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-kNN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/28/kNN/" class="article-date">
  <time datetime="2017-12-28T03:56:02.000Z" itemprop="datePublished">2017-12-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/28/kNN/">k-近邻算法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="k-近邻算法"><a href="#k-近邻算法" class="headerlink" title="k-近邻算法"></a>k-近邻算法</h2><hr>
<p>优点：精度高，对异常值不敏感、无数据输入假定</p>
<p>缺点：计算复杂度高、空间复杂度高</p>
<p>适用范围：数值型和标量型</p>
<hr>
<h3 id="k近邻算法的一般流程"><a href="#k近邻算法的一般流程" class="headerlink" title="k近邻算法的一般流程"></a>k近邻算法的一般流程</h3><ol>
<li>收集数据：可以使用任何方法</li>
<li>准备数据：距离计算所需要的数值，最好是结构化的数据格式</li>
<li>分析数据：any</li>
<li>训练算法：kNN无需预训练</li>
<li>测试算法：计算错误率</li>
<li>使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理</li>
</ol>
        
          <p class="article-more-link">
            <a href="/2017/12/28/kNN/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2017/12/28/kNN/" data-id="cjce7u9eq000y5cwgyqx8x1do" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kNN-算法/">kNN 算法</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-机器学习固本强基系列之特征工程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/20/机器学习固本强基系列之特征工程/" class="article-date">
  <time datetime="2017-12-20T03:19:46.000Z" itemprop="datePublished">2017-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/20/机器学习固本强基系列之特征工程/">机器学习固本强基系列之特征工程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2017/12/20/机器学习固本强基系列之特征工程/" data-id="cjce7u9ga002m5cwgtabbl2b9" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">Next&raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/yespon" target="_blank" title="Github"></a>
      
      
            <a class="weibo" aria-hidden="true"  href="http://weibo.com/yespon" target="_blank" title="微博"></a>
      
      
              <a class="zhihu" aria-hidden="true"  href="http://www.zhihu.com/people/yespon" target="_blank" title="知乎"></a>
      
      
            <a class="email" aria-hidden="true"  href="mailto:yespon@qq.com" target="_blank" title="邮箱"></a>
      
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title categories">Categories</h3>
    <div class="widget" id="categories">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Framework-Tools/">Framework&Tools</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器技术/">服务器技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">19</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/">架构&设计</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/经典文摘/">经典文摘</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNN-AlexNet/" style="font-size: 14px; color: #00f">CNN AlexNet</a> <a href="/tags/CUDA-GPUs/" style="font-size: 14px; color: #00f">CUDA GPUs</a> <a href="/tags/LDAP/" style="font-size: 14px; color: #00f">LDAP</a> <a href="/tags/MQ/" style="font-size: 19.5px; color: #7741f7">MQ</a> <a href="/tags/Nginx/" style="font-size: 14px; color: #00f">Nginx</a> <a href="/tags/Sticky/" style="font-size: 14px; color: #00f">Sticky</a> <a href="/tags/Tensorflow/" style="font-size: 22.25px; color: #b362f2">Tensorflow</a> <a href="/tags/UUID/" style="font-size: 14px; color: #00f">UUID</a> <a href="/tags/decorator/" style="font-size: 14px; color: #00f">decorator</a> <a href="/tags/deeplearning-ai/" style="font-size: 25px; color: #ee82ee">deeplearning.ai</a> <a href="/tags/kNN-算法/" style="font-size: 16.75px; color: #3c21fb">kNN 算法</a> <a href="/tags/pandas-read-csv/" style="font-size: 14px; color: #00f">pandas read_csv</a> <a href="/tags/quarts/" style="font-size: 14px; color: #00f">quarts</a> <a href="/tags/schedule/" style="font-size: 14px; color: #00f">schedule</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #00f">tensorflow</a> <a href="/tags/似然估计-likehood/" style="font-size: 14px; color: #00f">似然估计 likehood</a> <a href="/tags/分布式/" style="font-size: 14px; color: #00f">分布式</a> <a href="/tags/反向代理/" style="font-size: 14px; color: #00f">反向代理</a> <a href="/tags/唯一性ID/" style="font-size: 14px; color: #00f">唯一性ID</a> <a href="/tags/性能指标/" style="font-size: 14px; color: #00f">性能指标</a> <a href="/tags/消息中间件/" style="font-size: 19.5px; color: #7741f7">消息中间件</a> <a href="/tags/神经网络-NN/" style="font-size: 14px; color: #00f">神经网络 NN</a> <a href="/tags/装饰器/" style="font-size: 14px; color: #00f">装饰器</a> <a href="/tags/集群/" style="font-size: 14px; color: #00f">集群</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/">改善深层神经网络——超参数调试、Batch正则化和程序框架</a>
          </li>
        
          <li>
            <a href="/2018/01/13/改善深层神经网络——优化算法/">改善深层神经网络——优化算法</a>
          </li>
        
          <li>
            <a href="/2018/01/12/改善深层神经网络——深度学习的实践方面/">改善深层神经网络——深度学习的实用层面</a>
          </li>
        
          <li>
            <a href="/2018/01/12/神经网络和深度学习——深层神经网络/">神经网络和深度学习——深层神经网络</a>
          </li>
        
          <li>
            <a href="/2018/01/11/DeepLearning-ai学习笔记/">DeepLearning.ai学习笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="http://yespon.github.io">yespon&#39;s blog</a>
            </li>
            
        </ul>
    </div>
</div>

  
    <!--微信公众号二维码-->

  <div class="widget-wrap">
    <h3 class="follow-title ">WeChat</h3>
    <div class="widget wechat-widget">
        <img src="/images/wechat_yespon.jpg" alt="扫码关注" width="250"/>
    </div>
  </div>


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 Yespon&nbsp;|&nbsp;
      Theme by <a href="https://github.com/yespon/hexo-theme-yespon/" target="_blank">Yespon</a>
    </div>
     <div id="footer-right">
      Contact&nbsp;|&nbsp;yespon#qq.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/categories" class="mobile-nav-link">Category</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script> 
  <script>
  var gitment = new Gitment({
    // id: '页面 ID', // 可选。默认为 location.href
    owner: 'yespon',
    repo: 'yespon.github.io',
    oauth: {
    client_id: '4ab181ded22ebacbab72',
    client_secret: 'c3cd3df382f34a5685a1608234223423248250f7',
    }
  })
  gitment.render(document.getElementById("gitment_comments"))
</script>


<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>