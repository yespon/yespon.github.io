<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Life Designer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Life Designer, design by oneself!">
<meta property="og:type" content="website">
<meta property="og:title" content="Life Designer">
<meta property="og:url" content="http://yespon.github.io/index.html">
<meta property="og:site_name" content="Life Designer">
<meta property="og:description" content="Life Designer, design by oneself!">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Designer">
<meta name="twitter:description" content="Life Designer, design by oneself!">
  
    <link rel="alternate" href="/atom.xml" title="Life Designer" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yespon.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/categories">Category</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Designer</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Life Designer, design by oneself!</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-TensorFlow-api-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/31/TensorFlow-api-1/" class="article-date">
  <time datetime="2018-01-31T15:24:08.000Z" itemprop="datePublished">2018-01-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/31/TensorFlow-api-1/">TensorFlow-api(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="TensorFlow-api-1-：tf-reduce-mean-这类函数"><a href="#TensorFlow-api-1-：tf-reduce-mean-这类函数" class="headerlink" title="TensorFlow-api(1)：tf.reduce_mean()这类函数"></a>TensorFlow-api(1)：tf.reduce_mean()这类函数</h1><p>在tensor的某一维度上，有一类求值的函数，如tf.reduce_max( )，tf.reduce_mean( )，tf.reduce_sum( )</p>
<h2 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean( )"></a>tf.reduce_mean( )</h2><ul>
<li>函数作用：</li>
</ul>
<p>沿着tensor的某一维度，计算元素的平均值。由于输出tensor的维度比原tensor的低，这类操作也叫降维。</p>
<ul>
<li><p>参数：</p>
<ul>
<li>reduce_mean(input_tensor,axis=None,keep_dims=False,name=None, reduction_indices=None)</li>
<li>input_tensor：需要降维的tensor。</li>
<li>axis：axis=none, 求全部元素的平均值；axis=0, 按列降维，求每列平均值；axis=1，按行降维，求每行平均值。</li>
<li>keep_dims：若值为True，可多行输出平均值。</li>
<li>name：自定义操作的名称。 </li>
<li>reduction_indices：axis的旧名，已停用。</li>
</ul>
</li>
<li><p>返回：</p>
</li>
</ul>
<p>降维后的tensor</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">x = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]])</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    x = sess.run(x)</div><div class="line"></div><div class="line">    mean1 = sess.run(tf.reduce_mean(x))</div><div class="line">    mean2 = sess.run(tf.reduce_mean(x, <span class="number">0</span>))</div><div class="line">    mean3 = sess.run(tf.reduce_mean(x, <span class="number">1</span>))</div><div class="line"></div><div class="line">    print(x)</div><div class="line">    print()</div><div class="line">    print(mean1)</div><div class="line">    print()</div><div class="line">    print(mean2)</div><div class="line">    print()</div><div class="line">    print(mean3)</div></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[[ 1.  2.  3.]</div><div class="line"> [ 4.  5.  6.]]</div><div class="line"></div><div class="line">3.5</div><div class="line"></div><div class="line">[ 2.5  3.5  4.5]</div><div class="line"></div><div class="line">[ 2.  5.]</div></pre></td></tr></table></figure>
<h2 id="tf-reduce-sum"><a href="#tf-reduce-sum" class="headerlink" title="tf.reduce_sum( )"></a>tf.reduce_sum( )</h2><ul>
<li>函数作用：</li>
</ul>
<p>沿着tensor的某一维度，计算元素的和。由于输出tensor的维度比原tensor的低，这类操作也叫降维。</p>
<ul>
<li><p>参数:</p>
<ul>
<li>reduce_sum(input_tensor, axis=None,keep_dims=False, name=None, reduction_indices=None) </li>
<li>input_tensor：需要降维的tensor。 </li>
<li>axis：axis=none, 求全部元素的和；axis=0, 按列降维，求每列元素的和；axis=1，按行降维，求每行元素的和。 </li>
<li>keep_dims：若值为True，则用长度为1的tensor形式，输出平均值。 </li>
<li>name：自定义操作的名称。 </li>
<li>reduction_indices：axis的旧名，已停用。</li>
</ul>
</li>
<li><p>返回： </p>
</li>
</ul>
<p>降维后的tensor</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">x = tf.constant([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])                    </div><div class="line"></div><div class="line"><span class="comment"># axis = none</span></div><div class="line">reduce_sum = tf.reduce_sum(x)                               </div><div class="line"></div><div class="line"><span class="comment"># axis = 0</span></div><div class="line">reduce_sum_axis0 = tf.reduce_sum(x, axis = <span class="number">0</span>)                </div><div class="line">resuce_sum_axis0_axis0 = tf.reduce_sum(reduce_sum_axis0)</div><div class="line"></div><div class="line"><span class="comment"># axis = 1</span></div><div class="line">reduce_sum_axis1 = tf.reduce_sum(x, <span class="number">1</span>)</div><div class="line">reduce_sum_axis1_axis0 = tf.reduce_sum(reduce_sum_axis1, <span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment"># axis = [0, 1] or axis = [1, 0] </span></div><div class="line">reduce_sum_axis_01 = tf.reduce_sum(x, [<span class="number">0</span>, <span class="number">1</span>])</div><div class="line">reduce_sum_axis_10 = tf.reduce_sum(x, [<span class="number">1</span>, <span class="number">0</span>])</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 构建session</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line"></div><div class="line">    <span class="comment"># 运行op定义的运算</span></div><div class="line">    x = sess.run(x)</div><div class="line"></div><div class="line">    result = sess.run(reduce_sum)</div><div class="line"></div><div class="line">    result_0 = sess.run(reduce_sum_axis0)</div><div class="line">    result_0_0 = sess.run(resuce_sum_axis0_axis0) </div><div class="line"></div><div class="line">    result_1 = sess.run(reduce_sum_axis1)</div><div class="line">    result_1_0 = sess.run(reduce_sum_axis1_axis0)</div><div class="line"></div><div class="line">    result_01 = sess.run(reduce_sum_axis_01)</div><div class="line">    result_10 = sess.run(reduce_sum_axis_10)</div><div class="line"></div><div class="line">    <span class="comment"># 输出运算结果</span></div><div class="line">    print(x)</div><div class="line">    print()</div><div class="line">    print(<span class="string">'shape of input_tensor x'</span>)</div><div class="line">    print(type(x))</div><div class="line">    print()</div><div class="line"></div><div class="line">    print(<span class="string">'不传入参数axis，默认x reduce到0维'</span>)</div><div class="line">    print(<span class="string">'result ='</span>, result)</div><div class="line">    print()</div><div class="line"></div><div class="line">    print(<span class="string">'传入参数axis = 0'</span>)</div><div class="line">    print(<span class="string">'result_0 ='</span>, result_0)</div><div class="line">    print()</div><div class="line">    print(<span class="string">'把 %s 沿0轴，再次reduce'</span> % str(result_0))    </div><div class="line">    print(<span class="string">'result_0_0 ='</span>, result_0_0)</div><div class="line">    print()</div><div class="line"></div><div class="line">    print(<span class="string">'传入参数axis = 1'</span>)</div><div class="line">    print(<span class="string">'result_1 ='</span>, result_1)</div><div class="line">    print()</div><div class="line">    print(<span class="string">'把 %s 沿0轴，再次reduce'</span> % str(result_1))</div><div class="line">    print(<span class="string">'result_1_0 ='</span>, result_1_0)</div><div class="line">    print()</div><div class="line"></div><div class="line">    print(<span class="string">'输入参数axis = [0, 1]'</span>)</div><div class="line">    print(<span class="string">'result_01 ='</span>, result_01)</div><div class="line">    print()</div><div class="line">    print(<span class="string">'输入参数axis = [1, 0]'</span>)</div><div class="line">    print(<span class="string">'result_10 ='</span>, result_10)</div></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[[ 1.  1.  1.]</div><div class="line"> [ 1.  1.  1.]]</div><div class="line"></div><div class="line">shape of input_tensor x</div><div class="line">&lt;class &apos;numpy.ndarray&apos;&gt;</div><div class="line"></div><div class="line">不传入参数axis，默认x reduce到0维</div><div class="line">result = 6.0</div><div class="line"></div><div class="line">传入参数axis = 0</div><div class="line">result_0 = [ 2.  2.  2.]</div><div class="line"></div><div class="line">把 [ 2.  2.  2.] 沿0轴，再次reduce</div><div class="line">result_0_0 = 6.0</div><div class="line"></div><div class="line">传入参数axis = 1</div><div class="line">result_1 = [ 3.  3.]</div><div class="line"></div><div class="line">把 [ 3.  3.] 沿0轴，再次reduce</div><div class="line">result_1_0 = 6.0</div><div class="line"></div><div class="line">输入参数axis = [0, 1]</div><div class="line">result_01 = 6.0</div><div class="line"></div><div class="line">输入参数axis = [1, 0]</div><div class="line">result_10 = 6.0</div></pre></td></tr></table></figure>
<h2 id="tf-reduce-max"><a href="#tf-reduce-max" class="headerlink" title="tf.reduce_max( )"></a>tf.reduce_max( )</h2><ul>
<li>函数作用：</li>
</ul>
<p>沿着tensor的某一维度，计算元素的最大值。</p>
<ul>
<li>参数： </li>
</ul>
<p>同以上函数</p>
<ul>
<li>返回： </li>
</ul>
<p>降维后的tensor</p>
<h2 id="tf-reduce-min"><a href="#tf-reduce-min" class="headerlink" title="tf.reduce_min( )"></a>tf.reduce_min( )</h2><ul>
<li>函数作用：</li>
</ul>
<p>沿着tensor的某一维度，计算元素的最小值。</p>
<ul>
<li>参数： </li>
</ul>
<p>同以上函数</p>
<ul>
<li>返回： </li>
</ul>
<p>降维后的tensor</p>
<h2 id="tf-reduce-prod"><a href="#tf-reduce-prod" class="headerlink" title="tf.reduce_prod( )"></a>tf.reduce_prod( )</h2><ul>
<li>函数作用：</li>
</ul>
<p>沿着tensor的某一维度，计算输入tensor元素的乘积。</p>
<ul>
<li>参数： </li>
</ul>
<p>同以上函数</p>
<ul>
<li>返回： </li>
</ul>
<p>降维后的tensor</p>
<h2 id="tf-reduce-all"><a href="#tf-reduce-all" class="headerlink" title="tf.reduce_all( )"></a>tf.reduce_all( )</h2><ul>
<li>函数作用： </li>
</ul>
<p>对tensor中各个元素求逻辑‘与’。</p>
<ul>
<li>参数： </li>
</ul>
<p>同以上函数</p>
<ul>
<li>返回： </li>
</ul>
<p>降维后的tensor</p>
<h2 id="tf-reduce-any"><a href="#tf-reduce-any" class="headerlink" title="tf.reduce_any( )"></a>tf.reduce_any( )</h2><ul>
<li>函数作用： </li>
</ul>
<p>对tensor中各个元素求逻辑‘或’。</p>
<ul>
<li>参数： </li>
</ul>
<p>同以上函数</p>
<ul>
<li>返回： </li>
</ul>
<p>降维后的tensor</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/31/TensorFlow-api-1/" data-id="cjd38gnyd000fqgwg2g6acilm" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  
    <article id="post-简单有效的多标准中文分词" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/22/简单有效的多标准中文分词/" class="article-date">
  <time datetime="2018-01-22T07:40:02.000Z" itemprop="datePublished">2018-01-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/22/简单有效的多标准中文分词/">简单有效的多标准中文分词</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>本文介绍一种简洁优雅的多标准中文分词方案，可联合多个不同标准的语料库训练单个模型，同时输出多标准的分词结果。通过不同语料库之间的迁移学习提升模型的性能，在10个语料库上的联合试验结果优于绝大部分单独训练的模型。模型参数和超参数全部共享，复杂度不随语料库种类增长。</p>
<hr>
<p>论文：<a href="https://arxiv.org/abs/1712.02856" target="_blank" rel="external">https://arxiv.org/abs/1712.02856</a></p>
<h2 id="代码和语料：https-github-com-hankcs-multi-criteria-cws"><a href="#代码和语料：https-github-com-hankcs-multi-criteria-cws" class="headerlink" title="代码和语料：https://github.com/hankcs/multi-criteria-cws"></a>代码和语料：<a href="https://github.com/hankcs/multi-criteria-cws" target="_blank" rel="external">https://github.com/hankcs/multi-criteria-cws</a></h2><p>自然语言处理，特别是中文处理中，语料库往往珍稀且珍贵。具体到中文分词，也是如此。为了做出一个实用的系统，不光需要高效的算法，大规模语料库也必不可少。然而对于缺乏经费的研究团队和个人，却往往只能得到sighan2005等屈指可数的几个小型语料库。即便如此，这些语料库的标注规范还互不兼容，无法混合起来训练：<br>different-segmentation-criteria<br>比如PKU的最大特点就是姓名拆分为“姓”+“名”，MSR的标志则是命名实体构成大量长单词，而港台地区的语言习惯本来就与大陆不同。这些差异导致无法简单合并各方语料形成一个更大量级的语料库，只能在某一个语料库上训练，浪费了其他标注数据。<br>已经有工作开始研究如何利用多方语料库来联合学习中文分词，比如 Chen 20171精心设计的对抗神经网络，针对每个语料库提取分词标准相关或无关的特征。然而该工作并没有达到前沿的准确率，甚至联合训练的成绩还比不上以前单独训练的分数，无法体现联合学习的本意与优势。<br>事实上，这些标注风格迥异的分词语料像极了机器翻译中的多国语言：表达类似的意思，却采用了不同的方式。以前的多语种互译系统也是需要针对每个语种pair设计一对encoder-decoder：<br>previous-translation<br>图片转自斯坦福大学CS224n讲义<br>对nn种语言来讲，就需要n×(n−1)n×(n−1)对encoder-decoder。类似地，针对每个分词语料库设计网络层的话，对nn种分词标准，就需要nn个私有层。这样的系统臃肿不堪，过度复杂，也无法应对Zero-Shot Translation问题（缺乏某两个语言之间的平行语料）。<br>谷歌的解决方案说来简单，却不失优雅。聪明之处在于不修改网络架构，而是在输入数据上做文章。只需在输入平行语料pair中人工加入目标语种的标识符，就可以把所有语种的平行语料混合在一起训练了：<br>google-nmt<br>图片转自斯坦福大学CS224n讲义<br>这的确是长期跟工业生产线打交道的人才能想出来的实用方法。<br>受谷歌的多语种翻译系统启发，我们发现只需在句子首尾添加一对标识符，即可平滑无缝地将多标准语料库混合起来训练。具体做法是用一对闭合的<dataset> </dataset>将每个句子包裹起来：<br>token<br>接下来就可以通过大家熟悉的Bi-LSTM-CRF等序列标注模型联合训练了。在具体联合训练中，将这两个人工标识符视作普通字符即可，也不必人工区分句子的来源。这两个人工标识符会提示RNN这个句子属于哪种分词标准，使其为每个字符生成的contexual representation都受到该分词标准的影响。<br>在测试的时候，这两个人工标识符起到指定所需分词标准的作用。当然，公平起见标识符并不计入准确率的计算。<br>代码<br>连同语料库一起开源在GitHub上：<a href="https://github.com/hankcs/multi-criteria-cws" target="_blank" rel="external">https://github.com/hankcs/multi-criteria-cws</a> 。<br>调用脚本只需一两句话，请参考GitHub上的说明。<br>更多细节，请参考论文。<br>结果<br>我们在标准的sighan2005和sighan2008上做了实验，在没有针对性调参的情况下依然取得了更高的成绩（当时设备条件简陋，所以在所有数据集上都用了同一套超参数）。所有分值都通过了官方评测脚本的验算。<br>sighan2005<br>下图的baseline是在各个语料库上单独训练的结果，+multi是联合训练的结果。<br>sighan2005<br>sighan2008<br>我们也在标准的sighan2008上做了相同的试验，结果是：<br>sighan2008<br>值得一提的是，我们并没有针对sighan2005和sighan2008分别调参，而是放弃调参、在所有数据集上沿用了PKU的超参数。这是由于我们简陋的设备条件限制；欢迎计算力充裕的朋友自行调参，或许能有更好的结果。<br>10in1<br>由于sighan2008语料库是收费的，难以获取，没有授权的情况下也无法二次发布。同时我们不希望收费语料库成为阻碍小团队与个人研究者的壁垒，所以我们在1010个公开的语料库上做了额外的试验。<br>这1010个语料库分别是来自sighan2005的44份语料库以及<br>Universal Dependencies Project的UDC (Universal Dependencies Treebank Chinese)<br>由 Stanford CoreNLP 公开的 CTB6 (Chinese Tree Bank 6)<br>由山西大学发布的 SXU<br>由国家语委公布的 CNC 语料库<br>由王威廉老师公开的微博树库 WTB (Wang et al. 2014 2)<br>由张梅山老师公开的诛仙语料库 ZX (Zhang et al. 2014 3)。<br>语料库的授权信息如下（如有错误，欢迎反馈）：<br>licence<br>虽然部分语料库不常见于文献，但它们所属领域不同（新闻、微博、小说、港台）、数据规模迥异，恰好可以用来检验多标准分词模型的泛用性。我们的测试结果是：<br>10in1<br>(备注：此处与 Chen 2017 无法构成直接比较）<br>由于RNN训练很慢，为了方便复现结果，我们提供包含随机数在内的命令行：<br>./script/train.sh joint-10in1 –dynet-seed 10364 –python-seed 840868838938890892<br>除非依赖类库版本变迁，否则应该能够保证复现我们的结果。<br>我们还考察了这些人工标识符所起的作用，将它们的embedding通过t-SNE可视化出来后，发现几乎没有显著的相似性：<br>vectors.png<br>它们似乎起的作用都不相同。<br>结论<br>这是一种简单的多标注中文分词解决方案，可以在不增加模型复杂度的情况下联合多个语料库训练单个模型。该方案虽然简单，但的确带来了显著的性能提升（特别是对于小数据集如WTB）。同时我们也注意到特别大的数据集受益很小或无法从中受益（MSR），留作未来研究。我们希望该方法成为多标准中文分词的一个baseline，或生产系统中的一个物美价廉的拓展。<br>这是我的第一篇NLP论文，肯定有不少错误，欢迎指出。任何语法、拼写、行文上的错误和建议，欢迎留言，我会及时更正。谢谢！<br>鸣谢<br>感谢在试验器材不足时伸出援手的朋友们，以及对论文和试验施以援手的同学！<br>感谢那些慷慨地公开了标注语料库的老师与研究者们，这对没有研究经费的小团队而言无疑是雪中送炭！<br>Bi-LSTM-CRF模型的实现参考了rguthrie3的Dynet1.x版本。<br>References<br>X. Chen, Z. Shi, X. Qiu, and X. Huang, “Adversarial Multi-Criteria Learning for Chinese Word Segmentation.,” vol. 1704, p. arXiv:1704.07556, 2017. ↑<br>William Yang Wang, Lingpeng Kong, Kathryn Mazaitis, and William W Cohen. 2014. Dependency Parsing for Weibo - An Efficient Probabilistic Logic Programming Approach. EMNLP . ↑<br>Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2014. Type-Supervised Domain Adaptation for Joint Segmentation and POS-Tagging. EACL . ↑<br>知识共享许可协议 知识共享署名-非商业性使用-相同方式共享：码农场 » 简单有效的多标准中文分词</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/22/简单有效的多标准中文分词/" data-id="cjd38go0n003dqgwgrg30k3dj" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习总结/">机器学习总结</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-线性模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/19/线性模型/" class="article-date">
  <time datetime="2018-01-19T14:18:45.000Z" itemprop="datePublished">2018-01-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/19/线性模型/">线性模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="机器学习——线性模型"><a href="#机器学习——线性模型" class="headerlink" title="机器学习——线性模型"></a>机器学习——线性模型</h1><h2 id="广义线性模型（Generalized-Linear-Models）"><a href="#广义线性模型（Generalized-Linear-Models）" class="headerlink" title="广义线性模型（Generalized Linear Models）"></a>广义线性模型（Generalized Linear Models）</h2><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="均方误差最小化算法"><a href="#均方误差最小化算法" class="headerlink" title="均方误差最小化算法"></a>均方误差最小化算法</h3><p>基于均方误差最小化来进行模型求解的方法称为“最小二乘法（least square method）”。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小。</p>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>岭回归(英文名：ridge regression, Tikhonov regularization)是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。</p>
<h3 id="正则化算法"><a href="#正则化算法" class="headerlink" title="正则化算法"></a>正则化算法</h3><h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><h2 id="多元逻辑回归（Softmax-Regression）"><a href="#多元逻辑回归（Softmax-Regression）" class="headerlink" title="多元逻辑回归（Softmax Regression）"></a>多元逻辑回归（Softmax Regression）</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/19/线性模型/" data-id="cjd38go0n003fqgwgnu4ubosx" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习总结/">机器学习总结</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-结构化机器学习项目——机器学习策略-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/15/结构化机器学习项目——机器学习策略-2/" class="article-date">
  <time datetime="2018-01-15T04:35:55.000Z" itemprop="datePublished">2018-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/15/结构化机器学习项目——机器学习策略-2/">结构化机器学习项目——机器学习策略(2)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习策略-2"><a href="#机器学习策略-2" class="headerlink" title="机器学习策略(2)"></a>机器学习策略(2)</h1><h2 id="进行误差分析"><a href="#进行误差分析" class="headerlink" title="进行误差分析"></a>进行误差分析</h2><p>当我们在训练一个模型的时候，如一个猫和狗分类模型，最终得到了 90\% 的精确度，即有 10\% 的错误率。所以我们需要对模型做相应调整，才能更好地提升分类的精度。但是，这需要我们花费很长时间才能得到结果，可是这样做是否值得？<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-2/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/15/结构化机器学习项目——机器学习策略-2/" data-id="cjd38go0n003lqgwgrfnb537z" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-结构化机器学习项目——机器学习策略-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/15/结构化机器学习项目——机器学习策略-1/" class="article-date">
  <time datetime="2018-01-15T04:35:49.000Z" itemprop="datePublished">2018-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/15/结构化机器学习项目——机器学习策略-1/">结构化机器学习项目——机器学习策略(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习策略-1"><a href="#机器学习策略-1" class="headerlink" title="机器学习策略(1)"></a>机器学习策略(1)</h1><h2 id="为什么是ML策略"><a href="#为什么是ML策略" class="headerlink" title="为什么是ML策略"></a>为什么是ML策略</h2><p>假如我们在构建一个喵咪分类器，数据集就是上面几个图，训练之后准确率达到90%。虽然看起来挺高的，但是这显然并不具一般性，因为数据集太少了。那么此时可以想到的ML策略有哪些呢？<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-1/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/15/结构化机器学习项目——机器学习策略-1/" data-id="cjd38go0n003iqgwg9lwd2hgc" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——超参数调试、Batch正则化和程序框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" class="article-date">
  <time datetime="2018-01-14T02:39:49.000Z" itemprop="datePublished">2018-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/">改善深层神经网络——超参数调试、Batch正则化和程序框架</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="超参数调试、Batch正则化和程序框架"><a href="#超参数调试、Batch正则化和程序框架" class="headerlink" title="超参数调试、Batch正则化和程序框架"></a>超参数调试、Batch正则化和程序框架</h1><h2 id="超参数的调试处理"><a href="#超参数的调试处理" class="headerlink" title="超参数的调试处理"></a>超参数的调试处理</h2><p>在机器学习领域，超参数比较少，我们之前利用设置网格点的方式来调试超参数；<br>但在深度学习领域，超参数较多，不再是设置规则的网格点，而是随机选择点进行调试。这样做是因为，在我们处理问题的时候，无法知道哪个超参数更为重要，随机的方式测试超参数点的性能更为合理，可以探究超参数的潜在价值。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/14/改善深层神经网络——超参数调试、Batch正则化和程序框架/" data-id="cjd38gnzt0023qgwgnuyma6ks" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——优化算法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/13/改善深层神经网络——优化算法/" class="article-date">
  <time datetime="2018-01-13T12:41:17.000Z" itemprop="datePublished">2018-01-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/13/改善深层神经网络——优化算法/">改善深层神经网络——优化算法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="Mini-batch-梯度下降法"><a href="#Mini-batch-梯度下降法" class="headerlink" title="Mini-batch 梯度下降法"></a>Mini-batch 梯度下降法</h2><p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/13/改善深层神经网络——优化算法/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/13/改善深层神经网络——优化算法/" data-id="cjd38gnzj001wqgwg4b7dnl88" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-改善深层神经网络——深度学习的实践方面" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/12/改善深层神经网络——深度学习的实践方面/" class="article-date">
  <time datetime="2018-01-12T12:09:15.000Z" itemprop="datePublished">2018-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/12/改善深层神经网络——深度学习的实践方面/">改善深层神经网络——深度学习的实用层面</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="深度学习的实用层面"><a href="#深度学习的实用层面" class="headerlink" title="深度学习的实用层面"></a>深度学习的实用层面</h1><h2 id="训练-验证-测试集"><a href="#训练-验证-测试集" class="headerlink" title="训练/验证/测试集"></a>训练/验证/测试集</h2><p>对于一个需要解决的问题的样本数据，在建立模型的过程中，我们会将问题的data划分为以下几个部分：</p>
<ol>
<li><strong>训练集（train set）</strong>：用训练集对算法或模型进行训练过程；</li>
<li><strong>验证集（development set）</strong>：利用验证集或者又称为简单交叉验证集（hold-out cross validation set）进行交叉验证，选择出最好的模型；</li>
<li><strong>测试集（test set）</strong>：最后利用测试集对模型进行测试，获取模型运行的无偏估计。</li>
</ol>
        
          <p class="article-more-link">
            <a href="/2018/01/12/改善深层神经网络——深度学习的实践方面/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/12/改善深层神经网络——深度学习的实践方面/" data-id="cjd38gnzt0020qgwgcnmh1x1a" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-神经网络和深度学习——深层神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/12/神经网络和深度学习——深层神经网络/" class="article-date">
  <time datetime="2018-01-12T01:29:05.000Z" itemprop="datePublished">2018-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/12/神经网络和深度学习——深层神经网络/">神经网络和深度学习——深层神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="深层神经网络"><a href="#深层神经网络" class="headerlink" title="深层神经网络"></a>深层神经网络</h1><h2 id="矩阵的维度"><a href="#矩阵的维度" class="headerlink" title="矩阵的维度"></a>矩阵的维度</h2><p>DNN结构示意图如图所示：</p>
<p><img src="/2018/01/12/神经网络和深度学习——深层神经网络/1.jpg" alt=""><br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/12/神经网络和深度学习——深层神经网络/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/12/神经网络和深度学习——深层神经网络/" data-id="cjd38go0d0033qgwgd8fkelhx" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-DeepLearning-ai学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/11/DeepLearning-ai学习笔记/" class="article-date">
  <time datetime="2018-01-11T13:19:48.000Z" itemprop="datePublished">2018-01-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/11/DeepLearning-ai学习笔记/">DeepLearning.ai学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>学习的东西一段时间不使用总归是需要回顾一下的，学而时习之嘛！更何况毕竟不再年轻-_-！在学习DeepLearning.ai的过程中，将自己认为较为核心的东西记录下来，以便之后进行复习。<br></p>
        
          <p class="article-more-link">
            <a href="/2018/01/11/DeepLearning-ai学习笔记/#more">继续阅读全文 »</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yespon.github.io/2018/01/11/DeepLearning-ai学习笔记/" data-id="cjd38gnxo0002qgwgyb0bogd4" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next&raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/yespon" target="_blank" title="Github"></a>
      
      
            <a class="weibo" aria-hidden="true"  href="http://weibo.com/yespon" target="_blank" title="微博"></a>
      
      
              <a class="zhihu" aria-hidden="true"  href="http://www.zhihu.com/people/yespon" target="_blank" title="知乎"></a>
      
      
            <a class="email" aria-hidden="true"  href="mailto:yespon@qq.com" target="_blank" title="邮箱"></a>
      
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title categories">Categories</h3>
    <div class="widget" id="categories">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Framework-Tools/">Framework&Tools</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器技术/">服务器技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">23</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/">架构&设计</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/架构-设计/经典文摘/">经典文摘</a><span class="category-list-count">5</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNN-AlexNet/" style="font-size: 14px; color: #00f">CNN AlexNet</a> <a href="/tags/CUDA-GPUs/" style="font-size: 14px; color: #00f">CUDA GPUs</a> <a href="/tags/LDAP/" style="font-size: 14px; color: #00f">LDAP</a> <a href="/tags/MQ/" style="font-size: 19.5px; color: #7741f7">MQ</a> <a href="/tags/Nginx/" style="font-size: 14px; color: #00f">Nginx</a> <a href="/tags/Sticky/" style="font-size: 14px; color: #00f">Sticky</a> <a href="/tags/Tensorflow/" style="font-size: 22.25px; color: #b362f2">Tensorflow</a> <a href="/tags/UUID/" style="font-size: 14px; color: #00f">UUID</a> <a href="/tags/decorator/" style="font-size: 14px; color: #00f">decorator</a> <a href="/tags/deeplearning-ai/" style="font-size: 25px; color: #ee82ee">deeplearning.ai</a> <a href="/tags/kNN-算法/" style="font-size: 16.75px; color: #3c21fb">kNN 算法</a> <a href="/tags/pandas-read-csv/" style="font-size: 14px; color: #00f">pandas read_csv</a> <a href="/tags/quarts/" style="font-size: 14px; color: #00f">quarts</a> <a href="/tags/schedule/" style="font-size: 14px; color: #00f">schedule</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #00f">tensorflow</a> <a href="/tags/似然估计-likehood/" style="font-size: 14px; color: #00f">似然估计 likehood</a> <a href="/tags/分布式/" style="font-size: 14px; color: #00f">分布式</a> <a href="/tags/反向代理/" style="font-size: 14px; color: #00f">反向代理</a> <a href="/tags/唯一性ID/" style="font-size: 14px; color: #00f">唯一性ID</a> <a href="/tags/性能指标/" style="font-size: 14px; color: #00f">性能指标</a> <a href="/tags/机器学习总结/" style="font-size: 16.75px; color: #3c21fb">机器学习总结</a> <a href="/tags/消息中间件/" style="font-size: 19.5px; color: #7741f7">消息中间件</a> <a href="/tags/神经网络-NN/" style="font-size: 14px; color: #00f">神经网络 NN</a> <a href="/tags/装饰器/" style="font-size: 14px; color: #00f">装饰器</a> <a href="/tags/集群/" style="font-size: 14px; color: #00f">集群</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/01/31/TensorFlow-api-1/">TensorFlow-api(1)</a>
          </li>
        
          <li>
            <a href="/2018/01/22/简单有效的多标准中文分词/">简单有效的多标准中文分词</a>
          </li>
        
          <li>
            <a href="/2018/01/19/线性模型/">线性模型</a>
          </li>
        
          <li>
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-2/">结构化机器学习项目——机器学习策略(2)</a>
          </li>
        
          <li>
            <a href="/2018/01/15/结构化机器学习项目——机器学习策略-1/">结构化机器学习项目——机器学习策略(1)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="http://yespon.github.io">yespon&#39;s blog</a>
            </li>
            
        </ul>
    </div>
</div>

  
    <!--微信公众号二维码-->

  <div class="widget-wrap">
    <h3 class="follow-title ">WeChat</h3>
    <div class="widget wechat-widget">
        <img src="/images/wechat_yespon.jpg" alt="扫码关注" width="250"/>
    </div>
  </div>


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 Yespon&nbsp;|&nbsp;
      Theme by <a href="https://github.com/yespon/hexo-theme-yespon/" target="_blank">Yespon</a>
    </div>
     <div id="footer-right">
      Contact&nbsp;|&nbsp;yespon#qq.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/categories" class="mobile-nav-link">Category</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script> 
  <script>
  var gitment = new Gitment({
    // id: '页面 ID', // 可选。默认为 location.href
    owner: 'yespon',
    repo: 'yespon.github.io',
    oauth: {
    client_id: '4ab181ded22ebacbab72',
    client_secret: 'c3cd3df382f34a5685a1608234223423248250f7',
    }
  })
  gitment.render(document.getElementById("gitment_comments"))
</script>


<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>